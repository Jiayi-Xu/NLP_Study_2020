{"cells": [{"metadata": {"trusted": true}, "cell_type": "code", "source": "import tensorflow as tf\ntf.__version__", "execution_count": 3, "outputs": [{"output_type": "execute_result", "execution_count": 3, "data": {"text/plain": "'2.0.0-beta1'"}, "metadata": {}}]}, {"metadata": {"trusted": true}, "cell_type": "code", "source": "ls", "execution_count": 15, "outputs": [{"output_type": "stream", "text": "\u001b[0m\u001b[01;34mckpt\u001b[0m/     \u001b[01;34mdatasets\u001b[0m/     \u001b[01;34m__MACOSX\u001b[0m/         seq2seq_pgn_tf2.zip  utils.zip\r\nckpt.zip  datasets.zip  \u001b[01;34mseq2seq_pgn_tf2\u001b[0m/  \u001b[01;34mutils\u001b[0m/\r\n", "name": "stdout"}]}, {"metadata": {"trusted": true}, "cell_type": "code", "source": "# !unzip -o utils.zip", "execution_count": 10, "outputs": []}, {"metadata": {"trusted": true}, "cell_type": "code", "source": "# !unzip -o seq2seq_pgn_tf2.zip", "execution_count": 8, "outputs": []}, {"metadata": {"trusted": true}, "cell_type": "code", "source": "# !unzip ckpt.zip", "execution_count": 12, "outputs": []}, {"metadata": {"trusted": true}, "cell_type": "code", "source": "# !unzip datasets.zip", "execution_count": 16, "outputs": []}, {"metadata": {}, "cell_type": "markdown", "source": "## Mode = train\n\n\u8bb0\u5f55\uff1a8\u5c0f\u65f6\u8bad\u7ec3\u4e86\u4e00\u4e2aepoch loss=4.0221"}, {"metadata": {"trusted": false}, "cell_type": "code", "source": "%run seq2seq_pgn_tf2/bin/main.py", "execution_count": null, "outputs": [{"output_type": "stream", "text": "Creating the vocab ...\nmax_size of vocab was specified as 30000; we now have 30000 words. Stopping reading.\nFinished constructing vocabulary of 30000 total words. Last word added: \u51cc\u4e71\nCreating the batcher ...\nWARNING:tensorflow:From /home/ma-user/anaconda3/envs/TensorFlow-1.13.1/lib/python3.6/site-packages/tensorflow/python/data/ops/dataset_ops.py:505: py_func (from tensorflow.python.ops.script_ops) is deprecated and will be removed in a future version.\nInstructions for updating:\ntf.py_func is deprecated in TF V2. Instead, there are two\n    options available in V2.\n    - tf.py_function takes a python function which manipulates tf eager\n    tensors instead of numpy arrays. It's easy to convert a tf eager tensor to\n    an ndarray (just call tensor.numpy()) but having access to eager tensors\n    means `tf.py_function`s can use accelerators such as GPUs as well as\n    being differentiable using a gradient tape.\n    - tf.numpy_function maintains the semantics of the deprecated tf.py_func\n    (it is not differentiable, and manipulates numpy arrays). It drops the\n    stateful argument making all functions stateful.\n    \n", "name": "stdout"}, {"output_type": "stream", "text": "WARNING:tensorflow:From /home/ma-user/anaconda3/envs/TensorFlow-1.13.1/lib/python3.6/site-packages/tensorflow/python/data/ops/dataset_ops.py:505: py_func (from tensorflow.python.ops.script_ops) is deprecated and will be removed in a future version.\nInstructions for updating:\ntf.py_func is deprecated in TF V2. Instead, there are two\n    options available in V2.\n    - tf.py_function takes a python function which manipulates tf eager\n    tensors instead of numpy arrays. It's easy to convert a tf eager tensor to\n    an ndarray (just call tensor.numpy()) but having access to eager tensors\n    means `tf.py_function`s can use accelerators such as GPUs as well as\n    being differentiable using a gradient tape.\n    - tf.numpy_function maintains the semantics of the deprecated tf.py_func\n    (it is not differentiable, and manipulates numpy arrays). It drops the\n    stateful argument making all functions stateful.\n    \n", "name": "stderr"}, {"output_type": "stream", "text": "Building the model ...\nCreating the checkpoint manager\nInitializing from scratch.\nStarting the training ...\nWARNING:tensorflow:From /home/ma-user/anaconda3/envs/TensorFlow-1.13.1/lib/python3.6/site-packages/tensorflow/python/ops/math_grad.py:1250: add_dispatch_support.<locals>.wrapper (from tensorflow.python.ops.array_ops) is deprecated and will be removed in a future version.\nInstructions for updating:\nUse tf.where in 2.0, which has the same broadcast rule as np.where\n", "name": "stdout"}, {"output_type": "stream", "text": "WARNING:tensorflow:From /home/ma-user/anaconda3/envs/TensorFlow-1.13.1/lib/python3.6/site-packages/tensorflow/python/ops/math_grad.py:1250: add_dispatch_support.<locals>.wrapper (from tensorflow.python.ops.array_ops) is deprecated and will be removed in a future version.\nInstructions for updating:\nUse tf.where in 2.0, which has the same broadcast rule as np.where\n", "name": "stderr"}, {"output_type": "stream", "text": "Epoch 1 Batch 100 Loss 6.6181\nEpoch 1 Batch 200 Loss 6.4455\nEpoch 1 Batch 300 Loss 6.2337\nEpoch 1 Batch 400 Loss 6.1223\nEpoch 1 Batch 500 Loss 6.0195\nEpoch 1 Batch 600 Loss 5.9697\nEpoch 1 Batch 700 Loss 5.8942\nEpoch 1 Batch 800 Loss 5.8355\nEpoch 1 Batch 900 Loss 5.7450\nEpoch 1 Batch 1000 Loss 5.6790\nEpoch 1 Batch 1100 Loss 5.5783\nEpoch 1 Batch 1200 Loss 5.5199\nEpoch 1 Batch 1300 Loss 5.4762\nEpoch 1 Batch 1400 Loss 5.4373\nEpoch 1 Batch 1500 Loss 5.4082\nEpoch 1 Batch 1600 Loss 5.3775\nEpoch 1 Batch 1700 Loss 5.3307\nEpoch 1 Batch 1800 Loss 5.2898\nEpoch 1 Batch 1900 Loss 5.2582\nEpoch 1 Batch 2000 Loss 5.2165\nEpoch 1 Batch 2100 Loss 5.1729\nEpoch 1 Batch 2200 Loss 5.1437\nEpoch 1 Batch 2300 Loss 5.0924\nEpoch 1 Batch 2400 Loss 5.0693\nEpoch 1 Batch 2500 Loss 5.0343\nEpoch 1 Batch 2600 Loss 5.0166\nEpoch 1 Batch 2700 Loss 4.9920\nEpoch 1 Batch 2800 Loss 4.9707\nEpoch 1 Batch 2900 Loss 4.9565\nEpoch 1 Batch 3000 Loss 4.9300\nEpoch 1 Batch 3100 Loss 4.9109\nEpoch 1 Batch 3200 Loss 4.8854\nEpoch 1 Batch 3300 Loss 4.8673\nEpoch 1 Batch 3400 Loss 4.8513\nEpoch 1 Batch 3500 Loss 4.8448\nEpoch 1 Batch 3600 Loss 4.8222\nEpoch 1 Batch 3700 Loss 4.8057\nEpoch 1 Batch 3800 Loss 4.7906\nEpoch 1 Batch 3900 Loss 4.7766\nEpoch 1 Batch 4000 Loss 4.7663\nEpoch 1 Batch 4100 Loss 4.7523\nEpoch 1 Batch 4200 Loss 4.7478\nEpoch 1 Batch 4300 Loss 4.7391\nEpoch 1 Batch 4400 Loss 4.7247\nEpoch 1 Batch 4500 Loss 4.7173\nEpoch 1 Batch 4600 Loss 4.7007\nEpoch 1 Batch 4700 Loss 4.6888\nEpoch 1 Batch 4800 Loss 4.6835\nEpoch 1 Batch 4900 Loss 4.6677\nEpoch 1 Batch 5000 Loss 4.6539\nEpoch 1 Batch 5100 Loss 4.6457\nEpoch 1 Batch 5200 Loss 4.6376\nEpoch 1 Batch 5300 Loss 4.6273\nEpoch 1 Batch 5400 Loss 4.6153\nEpoch 1 Batch 5500 Loss 4.6122\nEpoch 1 Batch 5600 Loss 4.6034\nEpoch 1 Batch 5700 Loss 4.5947\nEpoch 1 Batch 5800 Loss 4.5862\nEpoch 1 Batch 5900 Loss 4.5745\nEpoch 1 Batch 6000 Loss 4.5658\nEpoch 1 Batch 6100 Loss 4.5592\nEpoch 1 Batch 6200 Loss 4.5435\nEpoch 1 Batch 6300 Loss 4.5395\nEpoch 1 Batch 6400 Loss 4.5308\nEpoch 1 Batch 6500 Loss 4.5285\nEpoch 1 Batch 6600 Loss 4.5208\nEpoch 1 Batch 6700 Loss 4.5126\nEpoch 1 Batch 6800 Loss 4.4995\nEpoch 1 Batch 6900 Loss 4.4918\nEpoch 1 Batch 7000 Loss 4.4886\nEpoch 1 Batch 7100 Loss 4.4794\nEpoch 1 Batch 7200 Loss 4.4771\nEpoch 1 Batch 7300 Loss 4.4748\nEpoch 1 Batch 7400 Loss 4.4715\nEpoch 1 Batch 7500 Loss 4.4615\nEpoch 1 Batch 7600 Loss 4.4607\nEpoch 1 Batch 7700 Loss 4.4506\nEpoch 1 Batch 7800 Loss 4.4456\nEpoch 1 Batch 7900 Loss 4.4346\nEpoch 1 Batch 8000 Loss 4.4312\nEpoch 1 Batch 8100 Loss 4.4254\nEpoch 1 Batch 8200 Loss 4.4219\nEpoch 1 Batch 8300 Loss 4.4153\nEpoch 1 Batch 8400 Loss 4.4132\nEpoch 1 Batch 8500 Loss 4.4070\nEpoch 1 Batch 8600 Loss 4.4010\nEpoch 1 Batch 8700 Loss 4.3967\nEpoch 1 Batch 8800 Loss 4.3950\nEpoch 1 Batch 8900 Loss 4.3897\nEpoch 1 Batch 9000 Loss 4.3828\nEpoch 1 Batch 9100 Loss 4.3794\nEpoch 1 Batch 9200 Loss 4.3728\nEpoch 1 Batch 9300 Loss 4.3651\nEpoch 1 Batch 9400 Loss 4.3602\nEpoch 1 Batch 9500 Loss 4.3563\nEpoch 1 Batch 9600 Loss 4.3548\nEpoch 1 Batch 9700 Loss 4.3511\nEpoch 1 Batch 9800 Loss 4.3476\nEpoch 1 Batch 9900 Loss 4.3441\nEpoch 1 Batch 10000 Loss 4.3399\nEpoch 1 Batch 10100 Loss 4.3373\nEpoch 1 Batch 10200 Loss 4.3323\nEpoch 1 Batch 10300 Loss 4.3265\nEpoch 1 Batch 10400 Loss 4.3204\nEpoch 1 Batch 10500 Loss 4.3179\nEpoch 1 Batch 10600 Loss 4.3118\nEpoch 1 Batch 10700 Loss 4.3043\nEpoch 1 Batch 10800 Loss 4.2999\nEpoch 1 Batch 10900 Loss 4.2968\nEpoch 1 Batch 11000 Loss 4.2945\nEpoch 1 Batch 11100 Loss 4.2900\nEpoch 1 Batch 11200 Loss 4.2866\nEpoch 1 Batch 11300 Loss 4.2837\nEpoch 1 Batch 11400 Loss 4.2804\nEpoch 1 Batch 11500 Loss 4.2705\nEpoch 1 Batch 11600 Loss 4.2698\nEpoch 1 Batch 11700 Loss 4.2699\nEpoch 1 Batch 11800 Loss 4.2598\nEpoch 1 Batch 11900 Loss 4.2576\nEpoch 1 Batch 12000 Loss 4.2543\nEpoch 1 Batch 12100 Loss 4.2503\nEpoch 1 Batch 12200 Loss 4.2465\nEpoch 1 Batch 12300 Loss 4.2436\nEpoch 1 Batch 12400 Loss 4.2370\nEpoch 1 Batch 12500 Loss 4.2337\nEpoch 1 Batch 12600 Loss 4.2305\nEpoch 1 Batch 12700 Loss 4.2279\nEpoch 1 Batch 12800 Loss 4.2277\nEpoch 1 Batch 12900 Loss 4.2245\nEpoch 1 Batch 13000 Loss 4.2224\nEpoch 1 Batch 13100 Loss 4.2204\nEpoch 1 Batch 13200 Loss 4.2191\nEpoch 1 Batch 13300 Loss 4.2189\nEpoch 1 Batch 13400 Loss 4.2179\nEpoch 1 Batch 13500 Loss 4.2157\nEpoch 1 Batch 13600 Loss 4.2131\nEpoch 1 Batch 13700 Loss 4.2119\nEpoch 1 Batch 13800 Loss 4.2089\nEpoch 1 Batch 13900 Loss 4.2064\nEpoch 1 Batch 14000 Loss 4.2023\nEpoch 1 Batch 14100 Loss 4.1983\nEpoch 1 Batch 14200 Loss 4.1948\nEpoch 1 Batch 14300 Loss 4.1927\nEpoch 1 Batch 14400 Loss 4.1919\nEpoch 1 Batch 14500 Loss 4.1897\nEpoch 1 Batch 14600 Loss 4.1883\nEpoch 1 Batch 14700 Loss 4.1881\nEpoch 1 Batch 14800 Loss 4.1844\nEpoch 1 Batch 14900 Loss 4.1837\nEpoch 1 Batch 15000 Loss 4.1834\nEpoch 1 Batch 15100 Loss 4.1777\nEpoch 1 Batch 15200 Loss 4.1747\nEpoch 1 Batch 15300 Loss 4.1727\nEpoch 1 Batch 15400 Loss 4.1726\nEpoch 1 Batch 15500 Loss 4.1679\nEpoch 1 Batch 15600 Loss 4.1649\nEpoch 1 Batch 15700 Loss 4.1582\nEpoch 1 Batch 15800 Loss 4.1576\nEpoch 1 Batch 15900 Loss 4.1554\nEpoch 1 Batch 16000 Loss 4.1518\nEpoch 1 Batch 16100 Loss 4.1503\nEpoch 1 Batch 16200 Loss 4.1482\nEpoch 1 Batch 16300 Loss 4.1459\nEpoch 1 Batch 16400 Loss 4.1452\nEpoch 1 Batch 16500 Loss 4.1434\nEpoch 1 Batch 16600 Loss 4.1424\nEpoch 1 Batch 16700 Loss 4.1423\nEpoch 1 Batch 16800 Loss 4.1407\nEpoch 1 Batch 16900 Loss 4.1390\nEpoch 1 Batch 17000 Loss 4.1383\nEpoch 1 Batch 17100 Loss 4.1357\nEpoch 1 Batch 17200 Loss 4.1357\nEpoch 1 Batch 17300 Loss 4.1345\nEpoch 1 Batch 17400 Loss 4.1337\nEpoch 1 Batch 17500 Loss 4.1313\nEpoch 1 Batch 17600 Loss 4.1283\nEpoch 1 Batch 17700 Loss 4.1292\nEpoch 1 Batch 17800 Loss 4.1280\nEpoch 1 Batch 17900 Loss 4.1265\nEpoch 1 Batch 18000 Loss 4.1234\nEpoch 1 Batch 18100 Loss 4.1191\nEpoch 1 Batch 18200 Loss 4.1182\nEpoch 1 Batch 18300 Loss 4.1168\nEpoch 1 Batch 18400 Loss 4.1137\nEpoch 1 Batch 18500 Loss 4.1123\nEpoch 1 Batch 18600 Loss 4.1117\nEpoch 1 Batch 18700 Loss 4.1091\nEpoch 1 Batch 18800 Loss 4.1066\nEpoch 1 Batch 18900 Loss 4.1050\nEpoch 1 Batch 19000 Loss 4.1042\nEpoch 1 Batch 19100 Loss 4.1020\nEpoch 1 Batch 19200 Loss 4.1012\nEpoch 1 Batch 19300 Loss 4.0977\nEpoch 1 Batch 19400 Loss 4.0977\nEpoch 1 Batch 19500 Loss 4.0913\nEpoch 1 Batch 19600 Loss 4.0888\nEpoch 1 Batch 19700 Loss 4.0862\nEpoch 1 Batch 19800 Loss 4.0849\nEpoch 1 Batch 19900 Loss 4.0818\nEpoch 1 Batch 20000 Loss 4.0787\nEpoch 1 Batch 20100 Loss 4.0782\nEpoch 1 Batch 20200 Loss 4.0765\nEpoch 1 Batch 20300 Loss 4.0749\nEpoch 1 Batch 20400 Loss 4.0742\nEpoch 1 Batch 20500 Loss 4.0712\nEpoch 1 Batch 20600 Loss 4.0711\nEpoch 1 Batch 20700 Loss 4.0717\nEpoch 1 Batch 20800 Loss 4.0705\nEpoch 1 Batch 20900 Loss 4.0693\nEpoch 1 Batch 21000 Loss 4.0684\nEpoch 1 Batch 21100 Loss 4.0681\nEpoch 1 Batch 21200 Loss 4.0672\nEpoch 1 Batch 21300 Loss 4.0668\nEpoch 1 Batch 21400 Loss 4.0658\nEpoch 1 Batch 21500 Loss 4.0656\nEpoch 1 Batch 21600 Loss 4.0643\nEpoch 1 Batch 21700 Loss 4.0633\nEpoch 1 Batch 21800 Loss 4.0619\nEpoch 1 Batch 21900 Loss 4.0619\nEpoch 1 Batch 22000 Loss 4.0609\nEpoch 1 Batch 22100 Loss 4.0595\nEpoch 1 Batch 22200 Loss 4.0586\nEpoch 1 Batch 22300 Loss 4.0582\nEpoch 1 Batch 22400 Loss 4.0586\nEpoch 1 Batch 22500 Loss 4.0581\nEpoch 1 Batch 22600 Loss 4.0566\nEpoch 1 Batch 22700 Loss 4.0574\nEpoch 1 Batch 22800 Loss 4.0568\nEpoch 1 Batch 22900 Loss 4.0564\nEpoch 1 Batch 23000 Loss 4.0569\nEpoch 1 Batch 23100 Loss 4.0560\nEpoch 1 Batch 23200 Loss 4.0551\nEpoch 1 Batch 23300 Loss 4.0559\nEpoch 1 Batch 23400 Loss 4.0548\nEpoch 1 Batch 23500 Loss 4.0529\nEpoch 1 Batch 23600 Loss 4.0532\nEpoch 1 Batch 23700 Loss 4.0516\nEpoch 1 Batch 23800 Loss 4.0516\nEpoch 1 Batch 23900 Loss 4.0515\nEpoch 1 Batch 24000 Loss 4.0498\nEpoch 1 Batch 24100 Loss 4.0491\nEpoch 1 Batch 24200 Loss 4.0479\nEpoch 1 Batch 24300 Loss 4.0464\nEpoch 1 Batch 24400 Loss 4.0455\nEpoch 1 Batch 24500 Loss 4.0455\nEpoch 1 Batch 24600 Loss 4.0448\nEpoch 1 Batch 24700 Loss 4.0439\nEpoch 1 Batch 24800 Loss 4.0430\nEpoch 1 Batch 24900 Loss 4.0412\nEpoch 1 Batch 25000 Loss 4.0395\nEpoch 1 Batch 25100 Loss 4.0386\nEpoch 1 Batch 25200 Loss 4.0382\nEpoch 1 Batch 25300 Loss 4.0377\nEpoch 1 Batch 25400 Loss 4.0371\nEpoch 1 Batch 25500 Loss 4.0367\nEpoch 1 Batch 25600 Loss 4.0352\nEpoch 1 Batch 25700 Loss 4.0346\nEpoch 1 Batch 25800 Loss 4.0339\nEpoch 1 Batch 25900 Loss 4.0337\nEpoch 1 Batch 26000 Loss 4.0331\n", "name": "stdout"}, {"output_type": "stream", "text": "Epoch 1 Batch 26100 Loss 4.0322\nEpoch 1 Batch 26200 Loss 4.0329\nEpoch 1 Batch 26300 Loss 4.0322\nEpoch 1 Batch 26400 Loss 4.0304\nEpoch 1 Batch 26500 Loss 4.0300\nEpoch 1 Batch 26600 Loss 4.0289\nEpoch 1 Batch 26700 Loss 4.0279\nEpoch 1 Batch 26800 Loss 4.0281\nEpoch 1 Batch 26900 Loss 4.0272\nEpoch 1 Batch 27000 Loss 4.0278\nEpoch 1 Batch 27100 Loss 4.0276\nEpoch 1 Batch 27200 Loss 4.0267\nEpoch 1 Batch 27300 Loss 4.0258\nEpoch 1 Batch 27400 Loss 4.0255\nEpoch 1 Batch 27500 Loss 4.0242\nEpoch 1 Batch 27600 Loss 4.0223\nSaving checkpoint for epoch 1 at /home/ma-user/work/ckpt/pgn/checkpoint/ckpt-1 ,best loss 4.022120475769043\nEpoch 1 Loss 4.0221\nTime taken for 1 epoch 27140.68084836006 sec\n\nEpoch 2 Batch 100 Loss 3.5951\nEpoch 2 Batch 200 Loss 3.8922\nEpoch 2 Batch 300 Loss 3.8550\nEpoch 2 Batch 400 Loss 3.8505\nEpoch 2 Batch 500 Loss 3.8648\nEpoch 2 Batch 600 Loss 3.8714\nEpoch 2 Batch 700 Loss 3.8806\nEpoch 2 Batch 800 Loss 3.8807\n", "name": "stdout"}]}, {"metadata": {}, "cell_type": "markdown", "source": "## Mode = test\n\n\u6d4b\u8bd5\u4f7f\u7528\u6587\u4ef6AutoMaster_TestSet_100.csv  \u4e3aAutoMaster_TestSet.csv \u7684\u524d100\u6761\u6570\u636e"}, {"metadata": {"trusted": true}, "cell_type": "code", "source": "%run seq2seq_pgn_tf2/bin/main.py", "execution_count": 1, "outputs": [{"output_type": "stream", "text": "\r  0%|          | 0/100 [00:00<?, ?it/s]", "name": "stderr"}, {"output_type": "stream", "text": "Building the model ...\nCreating the vocab ...\nmax_size of vocab was specified as 30000; we now have 30000 words. Stopping reading.\nFinished constructing vocabulary of 30000 total words. Last word added: \u51cc\u4e71\nCreating the batcher ...\nWARNING:tensorflow:From /home/ma-user/anaconda3/envs/TensorFlow-1.13.1/lib/python3.6/site-packages/tensorflow/python/data/ops/dataset_ops.py:505: py_func (from tensorflow.python.ops.script_ops) is deprecated and will be removed in a future version.\nInstructions for updating:\ntf.py_func is deprecated in TF V2. Instead, there are two\n    options available in V2.\n    - tf.py_function takes a python function which manipulates tf eager\n    tensors instead of numpy arrays. It's easy to convert a tf eager tensor to\n    an ndarray (just call tensor.numpy()) but having access to eager tensors\n    means `tf.py_function`s can use accelerators such as GPUs as well as\n    being differentiable using a gradient tape.\n    - tf.numpy_function maintains the semantics of the deprecated tf.py_func\n    (it is not differentiable, and manipulates numpy arrays). It drops the\n    stateful argument making all functions stateful.\n    \nCreating the checkpoint manager\nModel restored\n", "name": "stdout"}, {"output_type": "stream", "text": "100%|\u2588\u2588\u2588\u2588\u2588\u2588\u2588\u2588\u2588\u2588| 100/100 [12:31<00:00,  7.52s/it]\n", "name": "stderr"}]}, {"metadata": {"trusted": true}, "cell_type": "code", "source": "ls datasets/", "execution_count": 2, "outputs": [{"output_type": "stream", "text": "2020_06_13_14_59_55_batch_size_3_epochs_5_max_length_inp_['max_dec_len']_embedding_dim_['embed_size'].csv\r\n2020_06_13_15_32_48_batch_size_3_epochs_5_max_length_inp_['max_dec_len']_embedding_dim_['embed_size'].csv\r\nAutoMaster_TestSet_100.csv\r\nAutoMaster_TestSet.csv\r\nAutoMaster_TrainSet.csv\r\nsentences.txt\r\ntest_set.seg_x.txt\r\ntrain_set.seg_x.txt\r\ntrain_set.seg_y.txt\r\nvocab.txt\r\nw2v.bin\r\nword2vec.txt\r\n", "name": "stdout"}]}, {"metadata": {"trusted": true}, "cell_type": "code", "source": "%run seq2seq_pgn_tf2/bin/main.py", "execution_count": 1, "outputs": [{"output_type": "stream", "text": "\r  0%|          | 0/100 [00:00<?, ?it/s]", "name": "stderr"}, {"output_type": "stream", "text": "Building the model ...\nCreating the vocab ...\nmax_size of vocab was specified as 30000; we now have 30000 words. Stopping reading.\nFinished constructing vocabulary of 30000 total words. Last word added: \u51cc\u4e71\nCreating the batcher ...\nWARNING:tensorflow:From /home/ma-user/anaconda3/envs/TensorFlow-1.13.1/lib/python3.6/site-packages/tensorflow/python/data/ops/dataset_ops.py:505: py_func (from tensorflow.python.ops.script_ops) is deprecated and will be removed in a future version.\nInstructions for updating:\ntf.py_func is deprecated in TF V2. Instead, there are two\n    options available in V2.\n    - tf.py_function takes a python function which manipulates tf eager\n    tensors instead of numpy arrays. It's easy to convert a tf eager tensor to\n    an ndarray (just call tensor.numpy()) but having access to eager tensors\n    means `tf.py_function`s can use accelerators such as GPUs as well as\n    being differentiable using a gradient tape.\n    - tf.numpy_function maintains the semantics of the deprecated tf.py_func\n    (it is not differentiable, and manipulates numpy arrays). It drops the\n    stateful argument making all functions stateful.\n    \nCreating the checkpoint manager\nModel restored\n", "name": "stdout"}, {"output_type": "stream", "text": "100%|\u2588\u2588\u2588\u2588\u2588\u2588\u2588\u2588\u2588\u2588| 100/100 [12:28<00:00,  7.48s/it]\n", "name": "stderr"}]}, {"metadata": {"trusted": true}, "cell_type": "code", "source": "import pandas as pd\ndata = pd.read_csv('result2.csv')\ndata", "execution_count": 4, "outputs": [{"output_type": "execute_result", "execution_count": 4, "data": {"text/plain": "     QID                                         Prediction\n0     Q1  \uff0c \uff0c \uff0c \uff0c \uff0c \uff0c \uff0c \uff0c \uff0c \uff0c \uff0c \uff0c \uff0c \uff0c \uff0c \uff0c \uff0c \uff0c \uff0c \uff0c \uff0c \uff0c \uff0c ...\n1     Q2  \uff01 \uff01 \uff01 \uff01 \uff01 \uff01 \uff01 \uff01 \uff01 \uff01 \uff01 \uff01 \uff01 \uff01 \uff01 \uff01 \uff01 \uff01 \uff01 \uff01 \uff01 \uff01 \uff01 ...\n2     Q3  \u4e86 \u4e86 \u4e86 \u4e86 \u4e86 \u4e86 \u4e86 \u4e86 \u4e86 \u4e86 \u4e86 \u4e86 \u4e86 \u4e86 \u4e86 \u4e86 \u4e86 \u4e86 \u4e86 \u4e86 \u4e86 \u4e86 \u4e86 ...\n3     Q4  \u3002 \u3002 \u3002 \u3002 \u3002 \u3002 \u3002 \u3002 \u3002 \u3002 \u3002 \u3002 \u3002 \u3002 \u3002 \u3002 \u3002 \u3002 \u3002 \u3002 \u3002 \u3002 \u3002 ...\n4     Q5  \uff01 \uff01 \uff01 \uff01 \uff01 \uff01 \uff01 \uff01 \uff01 \uff01 \uff01 \uff01 \uff01 \uff01 \uff01 \uff01 \uff01 \uff01 \uff01 \uff01 \uff01 \uff01 \uff01 ...\n5     Q6  \uff0c \uff0c \uff0c \uff0c \uff0c \uff0c \uff0c \uff0c \uff0c \uff0c \uff0c \uff0c \uff0c \uff0c \uff0c \uff0c \uff0c \uff0c \uff0c \uff0c \uff0c \uff0c \uff0c ...\n6     Q7  \u8bf4 \u8bf4 \u8bf4 \u8bf4 \u8bf4 \u8bf4 \u8bf4 \u8bf4 \u8bf4 \u8bf4 \u8bf4 \u8bf4 \u8bf4 \u8bf4 \u8bf4 \u8bf4 \u8bf4 \u8bf4 \u8bf4 \u8bf4 \u8bf4 \u8bf4 \u8bf4 ...\n7     Q8  \uff0c \uff0c \uff0c \uff0c \uff0c \uff0c \uff0c \uff0c \uff0c \uff0c \uff0c \uff0c \uff0c \uff0c \uff0c \uff0c \uff0c \uff0c \uff0c \uff0c \uff0c \uff0c \uff0c ...\n8     Q9  \u7684 \u7684 \u7684 \u7684 \u7684 \u7684 \u7684 \u7684 \u7684 \u7684 \u7684 \u7684 \u7684 \u7684 \u7684 \u7684 \u7684 \u7684 \u7684 \u7684 \u7684 \u7684 \u7684 ...\n9    Q10  \uff0c \uff0c \uff0c \uff0c \uff0c \uff0c \uff0c \uff0c \uff0c \uff0c \uff0c \uff0c \uff0c \uff0c \uff0c \uff0c \uff0c \uff0c \uff0c \uff0c \uff0c \uff0c \uff0c ...\n10   Q11  \u7684 \u7684 \u7684 \u7684 \u7684 \u7684 \u7684 \u7684 \u7684 \u7684 \u7684 \u7684 \u7684 \u7684 \u7684 \u7684 \u7684 \u7684 \u7684 \u7684 \u7684 \u7684 \u7684 ...\n11   Q12  \uff0c \uff0c \uff0c \uff0c \uff0c \uff0c \uff0c \uff0c \uff0c \uff0c \uff0c \uff0c \uff0c \uff0c \uff0c \uff0c \uff0c \uff0c \uff0c \uff0c \uff0c \uff0c \uff0c ...\n12   Q13  \uff0c \uff0c \uff0c \uff0c \uff0c \uff0c \uff0c \uff0c \uff0c \uff0c \uff0c \uff0c \uff0c \uff0c \uff0c \uff0c \uff0c \uff0c \uff0c \uff0c \uff0c \uff0c \uff0c ...\n13   Q14  \u8bf4 \u8bf4 \u8bf4 \u8bf4 \u8bf4 \u8bf4 \u8bf4 \u8bf4 \u8bf4 \u8bf4 \u8bf4 \u8bf4 \u8bf4 \u8bf4 \u8bf4 \u8bf4 \u8bf4 \u8bf4 \u8bf4 \u8bf4 \u8bf4 \u8bf4 \u8bf4 ...\n14   Q15  \uff0c \uff0c \uff0c \uff0c \uff0c \uff0c \uff0c \uff0c \uff0c \uff0c \uff0c \uff0c \uff0c \uff0c \uff0c \uff0c \uff0c \uff0c \uff0c \uff0c \uff0c \uff0c \uff0c ...\n15   Q16  \uff0c \uff0c \uff0c \uff0c \uff0c \uff0c \uff0c \uff0c \uff0c \uff0c \uff0c \uff0c \uff0c \uff0c \uff0c \uff0c \uff0c \uff0c \uff0c \uff0c \uff0c \uff0c \uff0c ...\n16   Q17  \uff0c \uff0c \uff0c \uff0c \uff0c \uff0c \uff0c \uff0c \uff0c \uff0c \uff0c \uff0c \uff0c \uff0c \uff0c \uff0c \uff0c \uff0c \uff0c \uff0c \uff0c \uff0c \uff0c ...\n17   Q18  \uff0c \uff0c \uff0c \uff0c \uff0c \uff0c \uff0c \uff0c \uff0c \uff0c \uff0c \uff0c \uff0c \uff0c \uff0c \uff0c \uff0c \uff0c \uff0c \uff0c \uff0c \uff0c \uff0c ...\n18   Q19  \u8bf4 \u8bf4 \u8bf4 \u8bf4 \u8bf4 \u8bf4 \u8bf4 \u8bf4 \u8bf4 \u8bf4 \u8bf4 \u8bf4 \u8bf4 \u8bf4 \u8bf4 \u8bf4 \u8bf4 \u8bf4 \u8bf4 \u8bf4 \u8bf4 \u8bf4 \u8bf4 ...\n19   Q20  \uff0c \uff0c \uff0c \uff0c \uff0c \uff0c \uff0c \uff0c \uff0c \uff0c \uff0c \uff0c \uff0c \uff0c \uff0c \uff0c \uff0c \uff0c \uff0c \uff0c \uff0c \uff0c \uff0c ...\n20   Q21  \uff0c \uff0c \uff0c \uff0c \uff0c \uff0c \uff0c \uff0c \uff0c \uff0c \uff0c \uff0c \uff0c \uff0c \uff0c \uff0c \uff0c \uff0c \uff0c \uff0c \uff0c \uff0c \uff0c ...\n21   Q22  \uff0c \uff0c \uff0c \uff0c \uff0c \uff0c \uff0c \uff0c \uff0c \uff0c \uff0c \uff0c \uff0c \uff0c \uff0c \uff0c \uff0c \uff0c \uff0c \uff0c \uff0c \uff0c \uff0c ...\n22   Q23  \uff0c \uff0c \uff0c \uff0c \uff0c \uff0c \uff0c \uff0c \uff0c \uff0c \uff0c \uff0c \uff0c \uff0c \uff0c \uff0c \uff0c \uff0c \uff0c \uff0c \uff0c \uff0c \uff0c ...\n23   Q24  \uff0c \uff0c \uff0c \uff0c \uff0c \uff0c \uff0c \uff0c \uff0c \uff0c \uff0c \uff0c \uff0c \uff0c \uff0c \uff0c \uff0c \uff0c \uff0c \uff0c \uff0c \uff0c \uff0c ...\n24   Q25  \u7684 \u7684 \u7684 \u7684 \u7684 \u7684 \u7684 \u7684 \u7684 \u7684 \u7684 \u7684 \u7684 \u7684 \u7684 \u7684 \u7684 \u7684 \u7684 \u7684 \u7684 \u7684 \u7684 ...\n25   Q26  \uff0c \uff0c \uff0c \uff0c \uff0c \uff0c \uff0c \uff0c \uff0c \uff0c \uff0c \uff0c \uff0c \uff0c \uff0c \uff0c \uff0c \uff0c \uff0c \uff0c \uff0c \uff0c \uff0c ...\n26   Q27  \u8bf4 \u8bf4 \u8bf4 \u8bf4 \u8bf4 \u8bf4 \u8bf4 \u8bf4 \u8bf4 \u8bf4 \u8bf4 \u8bf4 \u8bf4 \u8bf4 \u8bf4 \u8bf4 \u8bf4 \u8bf4 \u8bf4 \u8bf4 \u8bf4 \u8bf4 \u8bf4 ...\n27   Q28  \u7535\u74f6 \u7535\u74f6 \uff0c \uff0c \uff0c \uff0c \uff0c \uff0c \uff0c \uff0c \uff0c \uff0c \uff0c \uff0c \uff0c \uff0c \uff0c \uff0c \uff0c \uff0c \uff0c \uff0c ...\n28   Q29  \u8bf4 \u8bf4 \u8bf4 \u8bf4 \u8bf4 \u8bf4 \u8bf4 \u8bf4 \u8bf4 \u8bf4 \u8bf4 \u8bf4 \u8bf4 \u8bf4 \u8bf4 \u8bf4 \u8bf4 \u8bf4 \u8bf4 \u8bf4 \u8bf4 \u8bf4 \u8bf4 ...\n29   Q30  \uff0c \uff0c \uff0c \uff0c \uff0c \uff0c \uff0c \uff0c \uff0c \uff0c \uff0c \uff0c \uff0c \uff0c \uff0c \uff0c \uff0c \uff0c \uff0c \uff0c \uff0c \uff0c \uff0c ...\n..   ...                                                ...\n70   Q71  \uff0c \uff0c \uff0c \uff0c \uff0c \uff0c \uff0c \uff0c \uff0c \uff0c \uff0c \uff0c \uff0c \uff0c \uff0c \uff0c \uff0c \uff0c \uff0c \uff0c \uff0c \uff0c \uff0c ...\n71   Q72  \uff0c \uff0c \uff0c \uff0c \uff0c \uff0c \uff0c \uff0c \uff0c \uff0c \uff0c \uff0c \uff0c \uff0c \uff0c \uff0c \uff0c \uff0c \uff0c \uff0c \uff0c \uff0c \uff0c ...\n72   Q73  \u9700\u8981 \u9700\u8981 \u9700\u8981 \u9700\u8981 \u9700\u8981 \u9700\u8981 \u9700\u8981 \u9700\u8981 \u9700\u8981 \u9700\u8981 \u9700\u8981 \u9700\u8981 \u9700\u8981 \u9700\u8981 \u9700\u8981 \u9700...\n73   Q74  \u4e86 \u4e86 \u4e86 \u4e86 \u4e86 \u4e86 \u4e86 \u4e86 \u4e86 \u4e86 \u4e86 \u4e86 \u4e86 \u4e86 \u4e86 \u4e86 \u4e86 \u4e86 \u4e86 \u4e86 \u4e86 \u4e86 \u4e86 ...\n74   Q75  \uff0c \uff0c \uff0c \uff0c \uff0c \uff0c \uff0c \uff0c \uff0c \uff0c \uff0c \uff0c \uff0c \uff0c \uff0c \uff0c \uff0c \uff0c \uff0c \uff0c \uff0c \uff0c \uff0c ...\n75   Q76  \uff1f \uff1f \uff1f \uff1f \uff1f \uff1f \uff1f \uff1f \uff1f \uff1f \uff1f \uff1f \uff1f \uff1f \uff1f \uff1f \uff1f \uff1f \uff1f \uff1f \uff1f \uff1f \uff1f ...\n76   Q77  \uff0c \uff0c \uff0c \uff0c \uff0c \uff0c \uff0c \uff0c \uff0c \uff0c \uff0c \uff0c \uff0c \uff0c \uff0c \uff0c \uff0c \uff0c \uff0c \uff0c \uff0c \uff0c \uff0c ...\n77   Q78  \uff0c \uff0c \uff0c \uff0c \uff0c \uff0c \uff0c \uff0c \uff0c \uff0c \uff0c \uff0c \uff0c \uff0c \uff0c \uff0c \uff0c \uff0c \uff0c \uff0c \uff0c \uff0c \uff0c ...\n78   Q79  \u8bf4 \u8bf4 \u8bf4 \u8bf4 \u8bf4 \u8bf4 \u8bf4 \u8bf4 \u8bf4 \u8bf4 \u8bf4 \u8bf4 \u8bf4 \u8bf4 \u8bf4 \u8bf4 \u8bf4 \u8bf4 \u8bf4 \u8bf4 \u8bf4 \u8bf4 \u8bf4 ...\n79   Q80  \u4e07\u516c\u91cc \u4e07\u516c\u91cc \u3001 \u3001 \u3001 \u3001 \u3001 \u3001 \u3001 \u3001 \u3001 \u3001 \u3001 \u3001 \u3001 \u3001 \u3001 \u3001 \u3001 \u3001 \u3001 ...\n80   Q81  \uff0c \uff0c \uff0c \uff0c \uff0c \uff0c \uff0c \uff0c \uff0c \uff0c \uff0c \uff0c \uff0c \uff0c \uff0c \uff0c \uff0c \uff0c \uff0c \uff0c \uff0c \uff0c \uff0c ...\n81   Q82  \uff0c \uff0c \uff0c \uff0c \uff0c \uff0c \uff0c \uff0c \uff0c \uff0c \uff0c \uff0c \uff0c \uff0c \uff0c \uff0c \uff0c \uff0c \uff0c \uff0c \uff0c \uff0c \uff0c ...\n82   Q83  \u3002 \u3002 \u3002 \u3002 \u3002 \u3002 \u3002 \u3002 \u3002 \u3002 \u3002 \u3002 \u3002 \u3002 \u3002 \u3002 \u3002 \u3002 \u3002 \u3002 \u3002 \u3002 \u3002 ...\n83   Q84  \uff0c \uff0c \uff0c \uff0c \uff0c \uff0c \uff0c \uff0c \uff0c \uff0c \uff0c \uff0c \uff0c \uff0c \uff0c \uff0c \uff0c \uff0c \uff0c \uff0c \uff0c \uff0c \uff0c ...\n84   Q85  \u65b9\u5411 \u65b9\u5411 \u65b9\u5411 \u65b9\u5411 \u65b9\u5411 \u65b9\u5411 \u65b9\u5411 \u65b9\u5411 \u65b9\u5411 \u65b9\u5411 \u65b9\u5411 \u65b9\u5411 \u65b9\u5411 \u65b9\u5411 \u65b9\u5411 \u65b9...\n85   Q86  \uff0c \uff0c \uff0c \uff0c \uff0c \uff0c \uff0c \uff0c \uff0c \uff0c \uff0c \uff0c \uff0c \uff0c \uff0c \uff0c \uff0c \uff0c \uff0c \uff0c \uff0c \uff0c \uff0c ...\n86   Q87  \uff0c \uff0c \uff0c \uff0c \uff0c \uff0c \uff0c \uff0c \uff0c \uff0c \uff0c \uff0c \uff0c \uff0c \uff0c \uff0c \uff0c \uff0c \uff0c \uff0c \uff0c \uff0c \uff0c ...\n87   Q88  \uff0c \uff0c \uff0c \uff0c \uff0c \uff0c \uff0c \uff0c \uff0c \uff0c \uff0c \uff0c \uff0c \uff0c \uff0c \uff0c \uff0c \uff0c \uff0c \uff0c \uff0c \uff0c \uff0c ...\n88   Q89  \u8bf4 \u8bf4 \u8bf4 \u8bf4 \u8bf4 \u8bf4 \u8bf4 \u8bf4 \u8bf4 \u8bf4 \u8bf4 \u8bf4 \u8bf4 \u8bf4 \u8bf4 \u8bf4 \u8bf4 \u8bf4 \u8bf4 \u8bf4 \u8bf4 \u8bf4 \u8bf4 ...\n89   Q90  \u8bf4 \u8bf4 \u8bf4 \u8bf4 \u8bf4 \u8bf4 \u8bf4 \u8bf4 \u8bf4 \u8bf4 \u8bf4 \u8bf4 \u8bf4 \u8bf4 \u8bf4 \u8bf4 \u8bf4 \u8bf4 \u8bf4 \u8bf4 \u8bf4 \u8bf4 \u8bf4 ...\n90   Q91  \uff0c \uff0c \uff0c \uff0c \uff0c \uff0c \uff0c \uff0c \uff0c \uff0c \uff0c \uff0c \uff0c \uff0c \uff0c \uff0c \uff0c \uff0c \uff0c \uff0c \uff0c \uff0c \uff0c ...\n91   Q92  \u8bf4 \u8bf4 \u8bf4 \u8bf4 \u8bf4 \u8bf4 \u8bf4 \u8bf4 \u8bf4 \u8bf4 \u8bf4 \u8bf4 \u8bf4 \u8bf4 \u8bf4 \u8bf4 \u8bf4 \u8bf4 \u8bf4 \u8bf4 \u8bf4 \u8bf4 \u8bf4 ...\n92   Q93  \u4e86 \u4e86 \u4e86 \u4e86 \u4e86 \u4e86 \u4e86 \u4e86 \u4e86 \u4e86 \u4e86 \u4e86 \u4e86 \u4e86 \u4e86 \u4e86 \u4e86 \u4e86 \u4e86 \u4e86 \u4e86 \u4e86 \u4e86 ...\n93   Q94  \uff0c \uff0c \uff0c \uff0c \uff0c \uff0c \uff0c \uff0c \uff0c \uff0c \uff0c \uff0c \uff0c \uff0c \uff0c \uff0c \uff0c \uff0c \uff0c \uff0c \uff0c \uff0c \uff0c ...\n94   Q95  \uff0c \uff0c \uff0c \uff0c \uff0c \uff0c \uff0c \uff0c \uff0c \uff0c \uff0c \uff0c \uff0c \uff0c \uff0c \uff0c \uff0c \uff0c \uff0c \uff0c \uff0c \uff0c \uff0c ...\n95   Q96  \u68c0\u67e5\u4e00\u4e0b \u68c0\u67e5\u4e00\u4e0b \u68c0\u67e5\u4e00\u4e0b \u68c0\u67e5\u4e00\u4e0b \u68c0\u67e5\u4e00\u4e0b \u68c0\u67e5\u4e00\u4e0b \u68c0\u67e5\u4e00\u4e0b \u68c0\u67e5\u4e00\u4e0b \u68c0\u67e5\u4e00\u4e0b \u68c0...\n96   Q97  \u8bf4 \u8bf4 \u8bf4 \u8bf4 \u8bf4 \u8bf4 \u8bf4 \u8bf4 \u8bf4 \u8bf4 \u8bf4 \u8bf4 \u8bf4 \u8bf4 \u8bf4 \u8bf4 \u8bf4 \u8bf4 \u8bf4 \u8bf4 \u8bf4 \u8bf4 \u8bf4 ...\n97   Q98  \u8bf4 \u8bf4 \u8bf4 \u8bf4 \u8bf4 \u8bf4 \u8bf4 \u8bf4 \u8bf4 \u8bf4 \u8bf4 \u8bf4 \u8bf4 \u8bf4 \u8bf4 \u8bf4 \u8bf4 \u8bf4 \u8bf4 \u8bf4 \u8bf4 \u8bf4 \u8bf4 ...\n98   Q99  \uff0c \uff0c \uff0c \uff0c \uff0c \uff0c \uff0c \uff0c \uff0c \uff0c \uff0c \uff0c \uff0c \uff0c \uff0c \uff0c \uff0c \uff0c \uff0c \uff0c \uff0c \uff0c \uff0c ...\n99  Q100  \u7684 \u7684 \u7684 \u7684 \u7684 \u7684 \u7684 \u7684 \u7684 \u7684 \u7684 \u7684 \u7684 \u7684 \u7684 \u7684 \u7684 \u7684 \u7684 \u7684 \u7684 \u7684 \u7684 ...\n\n[100 rows x 2 columns]", "text/html": "<div>\n<style scoped>\n    .dataframe tbody tr th:only-of-type {\n        vertical-align: middle;\n    }\n\n    .dataframe tbody tr th {\n        vertical-align: top;\n    }\n\n    .dataframe thead th {\n        text-align: right;\n    }\n</style>\n<table border=\"1\" class=\"dataframe\">\n  <thead>\n    <tr style=\"text-align: right;\">\n      <th></th>\n      <th>QID</th>\n      <th>Prediction</th>\n    </tr>\n  </thead>\n  <tbody>\n    <tr>\n      <th>0</th>\n      <td>Q1</td>\n      <td>\uff0c \uff0c \uff0c \uff0c \uff0c \uff0c \uff0c \uff0c \uff0c \uff0c \uff0c \uff0c \uff0c \uff0c \uff0c \uff0c \uff0c \uff0c \uff0c \uff0c \uff0c \uff0c \uff0c ...</td>\n    </tr>\n    <tr>\n      <th>1</th>\n      <td>Q2</td>\n      <td>\uff01 \uff01 \uff01 \uff01 \uff01 \uff01 \uff01 \uff01 \uff01 \uff01 \uff01 \uff01 \uff01 \uff01 \uff01 \uff01 \uff01 \uff01 \uff01 \uff01 \uff01 \uff01 \uff01 ...</td>\n    </tr>\n    <tr>\n      <th>2</th>\n      <td>Q3</td>\n      <td>\u4e86 \u4e86 \u4e86 \u4e86 \u4e86 \u4e86 \u4e86 \u4e86 \u4e86 \u4e86 \u4e86 \u4e86 \u4e86 \u4e86 \u4e86 \u4e86 \u4e86 \u4e86 \u4e86 \u4e86 \u4e86 \u4e86 \u4e86 ...</td>\n    </tr>\n    <tr>\n      <th>3</th>\n      <td>Q4</td>\n      <td>\u3002 \u3002 \u3002 \u3002 \u3002 \u3002 \u3002 \u3002 \u3002 \u3002 \u3002 \u3002 \u3002 \u3002 \u3002 \u3002 \u3002 \u3002 \u3002 \u3002 \u3002 \u3002 \u3002 ...</td>\n    </tr>\n    <tr>\n      <th>4</th>\n      <td>Q5</td>\n      <td>\uff01 \uff01 \uff01 \uff01 \uff01 \uff01 \uff01 \uff01 \uff01 \uff01 \uff01 \uff01 \uff01 \uff01 \uff01 \uff01 \uff01 \uff01 \uff01 \uff01 \uff01 \uff01 \uff01 ...</td>\n    </tr>\n    <tr>\n      <th>5</th>\n      <td>Q6</td>\n      <td>\uff0c \uff0c \uff0c \uff0c \uff0c \uff0c \uff0c \uff0c \uff0c \uff0c \uff0c \uff0c \uff0c \uff0c \uff0c \uff0c \uff0c \uff0c \uff0c \uff0c \uff0c \uff0c \uff0c ...</td>\n    </tr>\n    <tr>\n      <th>6</th>\n      <td>Q7</td>\n      <td>\u8bf4 \u8bf4 \u8bf4 \u8bf4 \u8bf4 \u8bf4 \u8bf4 \u8bf4 \u8bf4 \u8bf4 \u8bf4 \u8bf4 \u8bf4 \u8bf4 \u8bf4 \u8bf4 \u8bf4 \u8bf4 \u8bf4 \u8bf4 \u8bf4 \u8bf4 \u8bf4 ...</td>\n    </tr>\n    <tr>\n      <th>7</th>\n      <td>Q8</td>\n      <td>\uff0c \uff0c \uff0c \uff0c \uff0c \uff0c \uff0c \uff0c \uff0c \uff0c \uff0c \uff0c \uff0c \uff0c \uff0c \uff0c \uff0c \uff0c \uff0c \uff0c \uff0c \uff0c \uff0c ...</td>\n    </tr>\n    <tr>\n      <th>8</th>\n      <td>Q9</td>\n      <td>\u7684 \u7684 \u7684 \u7684 \u7684 \u7684 \u7684 \u7684 \u7684 \u7684 \u7684 \u7684 \u7684 \u7684 \u7684 \u7684 \u7684 \u7684 \u7684 \u7684 \u7684 \u7684 \u7684 ...</td>\n    </tr>\n    <tr>\n      <th>9</th>\n      <td>Q10</td>\n      <td>\uff0c \uff0c \uff0c \uff0c \uff0c \uff0c \uff0c \uff0c \uff0c \uff0c \uff0c \uff0c \uff0c \uff0c \uff0c \uff0c \uff0c \uff0c \uff0c \uff0c \uff0c \uff0c \uff0c ...</td>\n    </tr>\n    <tr>\n      <th>10</th>\n      <td>Q11</td>\n      <td>\u7684 \u7684 \u7684 \u7684 \u7684 \u7684 \u7684 \u7684 \u7684 \u7684 \u7684 \u7684 \u7684 \u7684 \u7684 \u7684 \u7684 \u7684 \u7684 \u7684 \u7684 \u7684 \u7684 ...</td>\n    </tr>\n    <tr>\n      <th>11</th>\n      <td>Q12</td>\n      <td>\uff0c \uff0c \uff0c \uff0c \uff0c \uff0c \uff0c \uff0c \uff0c \uff0c \uff0c \uff0c \uff0c \uff0c \uff0c \uff0c \uff0c \uff0c \uff0c \uff0c \uff0c \uff0c \uff0c ...</td>\n    </tr>\n    <tr>\n      <th>12</th>\n      <td>Q13</td>\n      <td>\uff0c \uff0c \uff0c \uff0c \uff0c \uff0c \uff0c \uff0c \uff0c \uff0c \uff0c \uff0c \uff0c \uff0c \uff0c \uff0c \uff0c \uff0c \uff0c \uff0c \uff0c \uff0c \uff0c ...</td>\n    </tr>\n    <tr>\n      <th>13</th>\n      <td>Q14</td>\n      <td>\u8bf4 \u8bf4 \u8bf4 \u8bf4 \u8bf4 \u8bf4 \u8bf4 \u8bf4 \u8bf4 \u8bf4 \u8bf4 \u8bf4 \u8bf4 \u8bf4 \u8bf4 \u8bf4 \u8bf4 \u8bf4 \u8bf4 \u8bf4 \u8bf4 \u8bf4 \u8bf4 ...</td>\n    </tr>\n    <tr>\n      <th>14</th>\n      <td>Q15</td>\n      <td>\uff0c \uff0c \uff0c \uff0c \uff0c \uff0c \uff0c \uff0c \uff0c \uff0c \uff0c \uff0c \uff0c \uff0c \uff0c \uff0c \uff0c \uff0c \uff0c \uff0c \uff0c \uff0c \uff0c ...</td>\n    </tr>\n    <tr>\n      <th>15</th>\n      <td>Q16</td>\n      <td>\uff0c \uff0c \uff0c \uff0c \uff0c \uff0c \uff0c \uff0c \uff0c \uff0c \uff0c \uff0c \uff0c \uff0c \uff0c \uff0c \uff0c \uff0c \uff0c \uff0c \uff0c \uff0c \uff0c ...</td>\n    </tr>\n    <tr>\n      <th>16</th>\n      <td>Q17</td>\n      <td>\uff0c \uff0c \uff0c \uff0c \uff0c \uff0c \uff0c \uff0c \uff0c \uff0c \uff0c \uff0c \uff0c \uff0c \uff0c \uff0c \uff0c \uff0c \uff0c \uff0c \uff0c \uff0c \uff0c ...</td>\n    </tr>\n    <tr>\n      <th>17</th>\n      <td>Q18</td>\n      <td>\uff0c \uff0c \uff0c \uff0c \uff0c \uff0c \uff0c \uff0c \uff0c \uff0c \uff0c \uff0c \uff0c \uff0c \uff0c \uff0c \uff0c \uff0c \uff0c \uff0c \uff0c \uff0c \uff0c ...</td>\n    </tr>\n    <tr>\n      <th>18</th>\n      <td>Q19</td>\n      <td>\u8bf4 \u8bf4 \u8bf4 \u8bf4 \u8bf4 \u8bf4 \u8bf4 \u8bf4 \u8bf4 \u8bf4 \u8bf4 \u8bf4 \u8bf4 \u8bf4 \u8bf4 \u8bf4 \u8bf4 \u8bf4 \u8bf4 \u8bf4 \u8bf4 \u8bf4 \u8bf4 ...</td>\n    </tr>\n    <tr>\n      <th>19</th>\n      <td>Q20</td>\n      <td>\uff0c \uff0c \uff0c \uff0c \uff0c \uff0c \uff0c \uff0c \uff0c \uff0c \uff0c \uff0c \uff0c \uff0c \uff0c \uff0c \uff0c \uff0c \uff0c \uff0c \uff0c \uff0c \uff0c ...</td>\n    </tr>\n    <tr>\n      <th>20</th>\n      <td>Q21</td>\n      <td>\uff0c \uff0c \uff0c \uff0c \uff0c \uff0c \uff0c \uff0c \uff0c \uff0c \uff0c \uff0c \uff0c \uff0c \uff0c \uff0c \uff0c \uff0c \uff0c \uff0c \uff0c \uff0c \uff0c ...</td>\n    </tr>\n    <tr>\n      <th>21</th>\n      <td>Q22</td>\n      <td>\uff0c \uff0c \uff0c \uff0c \uff0c \uff0c \uff0c \uff0c \uff0c \uff0c \uff0c \uff0c \uff0c \uff0c \uff0c \uff0c \uff0c \uff0c \uff0c \uff0c \uff0c \uff0c \uff0c ...</td>\n    </tr>\n    <tr>\n      <th>22</th>\n      <td>Q23</td>\n      <td>\uff0c \uff0c \uff0c \uff0c \uff0c \uff0c \uff0c \uff0c \uff0c \uff0c \uff0c \uff0c \uff0c \uff0c \uff0c \uff0c \uff0c \uff0c \uff0c \uff0c \uff0c \uff0c \uff0c ...</td>\n    </tr>\n    <tr>\n      <th>23</th>\n      <td>Q24</td>\n      <td>\uff0c \uff0c \uff0c \uff0c \uff0c \uff0c \uff0c \uff0c \uff0c \uff0c \uff0c \uff0c \uff0c \uff0c \uff0c \uff0c \uff0c \uff0c \uff0c \uff0c \uff0c \uff0c \uff0c ...</td>\n    </tr>\n    <tr>\n      <th>24</th>\n      <td>Q25</td>\n      <td>\u7684 \u7684 \u7684 \u7684 \u7684 \u7684 \u7684 \u7684 \u7684 \u7684 \u7684 \u7684 \u7684 \u7684 \u7684 \u7684 \u7684 \u7684 \u7684 \u7684 \u7684 \u7684 \u7684 ...</td>\n    </tr>\n    <tr>\n      <th>25</th>\n      <td>Q26</td>\n      <td>\uff0c \uff0c \uff0c \uff0c \uff0c \uff0c \uff0c \uff0c \uff0c \uff0c \uff0c \uff0c \uff0c \uff0c \uff0c \uff0c \uff0c \uff0c \uff0c \uff0c \uff0c \uff0c \uff0c ...</td>\n    </tr>\n    <tr>\n      <th>26</th>\n      <td>Q27</td>\n      <td>\u8bf4 \u8bf4 \u8bf4 \u8bf4 \u8bf4 \u8bf4 \u8bf4 \u8bf4 \u8bf4 \u8bf4 \u8bf4 \u8bf4 \u8bf4 \u8bf4 \u8bf4 \u8bf4 \u8bf4 \u8bf4 \u8bf4 \u8bf4 \u8bf4 \u8bf4 \u8bf4 ...</td>\n    </tr>\n    <tr>\n      <th>27</th>\n      <td>Q28</td>\n      <td>\u7535\u74f6 \u7535\u74f6 \uff0c \uff0c \uff0c \uff0c \uff0c \uff0c \uff0c \uff0c \uff0c \uff0c \uff0c \uff0c \uff0c \uff0c \uff0c \uff0c \uff0c \uff0c \uff0c \uff0c ...</td>\n    </tr>\n    <tr>\n      <th>28</th>\n      <td>Q29</td>\n      <td>\u8bf4 \u8bf4 \u8bf4 \u8bf4 \u8bf4 \u8bf4 \u8bf4 \u8bf4 \u8bf4 \u8bf4 \u8bf4 \u8bf4 \u8bf4 \u8bf4 \u8bf4 \u8bf4 \u8bf4 \u8bf4 \u8bf4 \u8bf4 \u8bf4 \u8bf4 \u8bf4 ...</td>\n    </tr>\n    <tr>\n      <th>29</th>\n      <td>Q30</td>\n      <td>\uff0c \uff0c \uff0c \uff0c \uff0c \uff0c \uff0c \uff0c \uff0c \uff0c \uff0c \uff0c \uff0c \uff0c \uff0c \uff0c \uff0c \uff0c \uff0c \uff0c \uff0c \uff0c \uff0c ...</td>\n    </tr>\n    <tr>\n      <th>...</th>\n      <td>...</td>\n      <td>...</td>\n    </tr>\n    <tr>\n      <th>70</th>\n      <td>Q71</td>\n      <td>\uff0c \uff0c \uff0c \uff0c \uff0c \uff0c \uff0c \uff0c \uff0c \uff0c \uff0c \uff0c \uff0c \uff0c \uff0c \uff0c \uff0c \uff0c \uff0c \uff0c \uff0c \uff0c \uff0c ...</td>\n    </tr>\n    <tr>\n      <th>71</th>\n      <td>Q72</td>\n      <td>\uff0c \uff0c \uff0c \uff0c \uff0c \uff0c \uff0c \uff0c \uff0c \uff0c \uff0c \uff0c \uff0c \uff0c \uff0c \uff0c \uff0c \uff0c \uff0c \uff0c \uff0c \uff0c \uff0c ...</td>\n    </tr>\n    <tr>\n      <th>72</th>\n      <td>Q73</td>\n      <td>\u9700\u8981 \u9700\u8981 \u9700\u8981 \u9700\u8981 \u9700\u8981 \u9700\u8981 \u9700\u8981 \u9700\u8981 \u9700\u8981 \u9700\u8981 \u9700\u8981 \u9700\u8981 \u9700\u8981 \u9700\u8981 \u9700\u8981 \u9700...</td>\n    </tr>\n    <tr>\n      <th>73</th>\n      <td>Q74</td>\n      <td>\u4e86 \u4e86 \u4e86 \u4e86 \u4e86 \u4e86 \u4e86 \u4e86 \u4e86 \u4e86 \u4e86 \u4e86 \u4e86 \u4e86 \u4e86 \u4e86 \u4e86 \u4e86 \u4e86 \u4e86 \u4e86 \u4e86 \u4e86 ...</td>\n    </tr>\n    <tr>\n      <th>74</th>\n      <td>Q75</td>\n      <td>\uff0c \uff0c \uff0c \uff0c \uff0c \uff0c \uff0c \uff0c \uff0c \uff0c \uff0c \uff0c \uff0c \uff0c \uff0c \uff0c \uff0c \uff0c \uff0c \uff0c \uff0c \uff0c \uff0c ...</td>\n    </tr>\n    <tr>\n      <th>75</th>\n      <td>Q76</td>\n      <td>\uff1f \uff1f \uff1f \uff1f \uff1f \uff1f \uff1f \uff1f \uff1f \uff1f \uff1f \uff1f \uff1f \uff1f \uff1f \uff1f \uff1f \uff1f \uff1f \uff1f \uff1f \uff1f \uff1f ...</td>\n    </tr>\n    <tr>\n      <th>76</th>\n      <td>Q77</td>\n      <td>\uff0c \uff0c \uff0c \uff0c \uff0c \uff0c \uff0c \uff0c \uff0c \uff0c \uff0c \uff0c \uff0c \uff0c \uff0c \uff0c \uff0c \uff0c \uff0c \uff0c \uff0c \uff0c \uff0c ...</td>\n    </tr>\n    <tr>\n      <th>77</th>\n      <td>Q78</td>\n      <td>\uff0c \uff0c \uff0c \uff0c \uff0c \uff0c \uff0c \uff0c \uff0c \uff0c \uff0c \uff0c \uff0c \uff0c \uff0c \uff0c \uff0c \uff0c \uff0c \uff0c \uff0c \uff0c \uff0c ...</td>\n    </tr>\n    <tr>\n      <th>78</th>\n      <td>Q79</td>\n      <td>\u8bf4 \u8bf4 \u8bf4 \u8bf4 \u8bf4 \u8bf4 \u8bf4 \u8bf4 \u8bf4 \u8bf4 \u8bf4 \u8bf4 \u8bf4 \u8bf4 \u8bf4 \u8bf4 \u8bf4 \u8bf4 \u8bf4 \u8bf4 \u8bf4 \u8bf4 \u8bf4 ...</td>\n    </tr>\n    <tr>\n      <th>79</th>\n      <td>Q80</td>\n      <td>\u4e07\u516c\u91cc \u4e07\u516c\u91cc \u3001 \u3001 \u3001 \u3001 \u3001 \u3001 \u3001 \u3001 \u3001 \u3001 \u3001 \u3001 \u3001 \u3001 \u3001 \u3001 \u3001 \u3001 \u3001 ...</td>\n    </tr>\n    <tr>\n      <th>80</th>\n      <td>Q81</td>\n      <td>\uff0c \uff0c \uff0c \uff0c \uff0c \uff0c \uff0c \uff0c \uff0c \uff0c \uff0c \uff0c \uff0c \uff0c \uff0c \uff0c \uff0c \uff0c \uff0c \uff0c \uff0c \uff0c \uff0c ...</td>\n    </tr>\n    <tr>\n      <th>81</th>\n      <td>Q82</td>\n      <td>\uff0c \uff0c \uff0c \uff0c \uff0c \uff0c \uff0c \uff0c \uff0c \uff0c \uff0c \uff0c \uff0c \uff0c \uff0c \uff0c \uff0c \uff0c \uff0c \uff0c \uff0c \uff0c \uff0c ...</td>\n    </tr>\n    <tr>\n      <th>82</th>\n      <td>Q83</td>\n      <td>\u3002 \u3002 \u3002 \u3002 \u3002 \u3002 \u3002 \u3002 \u3002 \u3002 \u3002 \u3002 \u3002 \u3002 \u3002 \u3002 \u3002 \u3002 \u3002 \u3002 \u3002 \u3002 \u3002 ...</td>\n    </tr>\n    <tr>\n      <th>83</th>\n      <td>Q84</td>\n      <td>\uff0c \uff0c \uff0c \uff0c \uff0c \uff0c \uff0c \uff0c \uff0c \uff0c \uff0c \uff0c \uff0c \uff0c \uff0c \uff0c \uff0c \uff0c \uff0c \uff0c \uff0c \uff0c \uff0c ...</td>\n    </tr>\n    <tr>\n      <th>84</th>\n      <td>Q85</td>\n      <td>\u65b9\u5411 \u65b9\u5411 \u65b9\u5411 \u65b9\u5411 \u65b9\u5411 \u65b9\u5411 \u65b9\u5411 \u65b9\u5411 \u65b9\u5411 \u65b9\u5411 \u65b9\u5411 \u65b9\u5411 \u65b9\u5411 \u65b9\u5411 \u65b9\u5411 \u65b9...</td>\n    </tr>\n    <tr>\n      <th>85</th>\n      <td>Q86</td>\n      <td>\uff0c \uff0c \uff0c \uff0c \uff0c \uff0c \uff0c \uff0c \uff0c \uff0c \uff0c \uff0c \uff0c \uff0c \uff0c \uff0c \uff0c \uff0c \uff0c \uff0c \uff0c \uff0c \uff0c ...</td>\n    </tr>\n    <tr>\n      <th>86</th>\n      <td>Q87</td>\n      <td>\uff0c \uff0c \uff0c \uff0c \uff0c \uff0c \uff0c \uff0c \uff0c \uff0c \uff0c \uff0c \uff0c \uff0c \uff0c \uff0c \uff0c \uff0c \uff0c \uff0c \uff0c \uff0c \uff0c ...</td>\n    </tr>\n    <tr>\n      <th>87</th>\n      <td>Q88</td>\n      <td>\uff0c \uff0c \uff0c \uff0c \uff0c \uff0c \uff0c \uff0c \uff0c \uff0c \uff0c \uff0c \uff0c \uff0c \uff0c \uff0c \uff0c \uff0c \uff0c \uff0c \uff0c \uff0c \uff0c ...</td>\n    </tr>\n    <tr>\n      <th>88</th>\n      <td>Q89</td>\n      <td>\u8bf4 \u8bf4 \u8bf4 \u8bf4 \u8bf4 \u8bf4 \u8bf4 \u8bf4 \u8bf4 \u8bf4 \u8bf4 \u8bf4 \u8bf4 \u8bf4 \u8bf4 \u8bf4 \u8bf4 \u8bf4 \u8bf4 \u8bf4 \u8bf4 \u8bf4 \u8bf4 ...</td>\n    </tr>\n    <tr>\n      <th>89</th>\n      <td>Q90</td>\n      <td>\u8bf4 \u8bf4 \u8bf4 \u8bf4 \u8bf4 \u8bf4 \u8bf4 \u8bf4 \u8bf4 \u8bf4 \u8bf4 \u8bf4 \u8bf4 \u8bf4 \u8bf4 \u8bf4 \u8bf4 \u8bf4 \u8bf4 \u8bf4 \u8bf4 \u8bf4 \u8bf4 ...</td>\n    </tr>\n    <tr>\n      <th>90</th>\n      <td>Q91</td>\n      <td>\uff0c \uff0c \uff0c \uff0c \uff0c \uff0c \uff0c \uff0c \uff0c \uff0c \uff0c \uff0c \uff0c \uff0c \uff0c \uff0c \uff0c \uff0c \uff0c \uff0c \uff0c \uff0c \uff0c ...</td>\n    </tr>\n    <tr>\n      <th>91</th>\n      <td>Q92</td>\n      <td>\u8bf4 \u8bf4 \u8bf4 \u8bf4 \u8bf4 \u8bf4 \u8bf4 \u8bf4 \u8bf4 \u8bf4 \u8bf4 \u8bf4 \u8bf4 \u8bf4 \u8bf4 \u8bf4 \u8bf4 \u8bf4 \u8bf4 \u8bf4 \u8bf4 \u8bf4 \u8bf4 ...</td>\n    </tr>\n    <tr>\n      <th>92</th>\n      <td>Q93</td>\n      <td>\u4e86 \u4e86 \u4e86 \u4e86 \u4e86 \u4e86 \u4e86 \u4e86 \u4e86 \u4e86 \u4e86 \u4e86 \u4e86 \u4e86 \u4e86 \u4e86 \u4e86 \u4e86 \u4e86 \u4e86 \u4e86 \u4e86 \u4e86 ...</td>\n    </tr>\n    <tr>\n      <th>93</th>\n      <td>Q94</td>\n      <td>\uff0c \uff0c \uff0c \uff0c \uff0c \uff0c \uff0c \uff0c \uff0c \uff0c \uff0c \uff0c \uff0c \uff0c \uff0c \uff0c \uff0c \uff0c \uff0c \uff0c \uff0c \uff0c \uff0c ...</td>\n    </tr>\n    <tr>\n      <th>94</th>\n      <td>Q95</td>\n      <td>\uff0c \uff0c \uff0c \uff0c \uff0c \uff0c \uff0c \uff0c \uff0c \uff0c \uff0c \uff0c \uff0c \uff0c \uff0c \uff0c \uff0c \uff0c \uff0c \uff0c \uff0c \uff0c \uff0c ...</td>\n    </tr>\n    <tr>\n      <th>95</th>\n      <td>Q96</td>\n      <td>\u68c0\u67e5\u4e00\u4e0b \u68c0\u67e5\u4e00\u4e0b \u68c0\u67e5\u4e00\u4e0b \u68c0\u67e5\u4e00\u4e0b \u68c0\u67e5\u4e00\u4e0b \u68c0\u67e5\u4e00\u4e0b \u68c0\u67e5\u4e00\u4e0b \u68c0\u67e5\u4e00\u4e0b \u68c0\u67e5\u4e00\u4e0b \u68c0...</td>\n    </tr>\n    <tr>\n      <th>96</th>\n      <td>Q97</td>\n      <td>\u8bf4 \u8bf4 \u8bf4 \u8bf4 \u8bf4 \u8bf4 \u8bf4 \u8bf4 \u8bf4 \u8bf4 \u8bf4 \u8bf4 \u8bf4 \u8bf4 \u8bf4 \u8bf4 \u8bf4 \u8bf4 \u8bf4 \u8bf4 \u8bf4 \u8bf4 \u8bf4 ...</td>\n    </tr>\n    <tr>\n      <th>97</th>\n      <td>Q98</td>\n      <td>\u8bf4 \u8bf4 \u8bf4 \u8bf4 \u8bf4 \u8bf4 \u8bf4 \u8bf4 \u8bf4 \u8bf4 \u8bf4 \u8bf4 \u8bf4 \u8bf4 \u8bf4 \u8bf4 \u8bf4 \u8bf4 \u8bf4 \u8bf4 \u8bf4 \u8bf4 \u8bf4 ...</td>\n    </tr>\n    <tr>\n      <th>98</th>\n      <td>Q99</td>\n      <td>\uff0c \uff0c \uff0c \uff0c \uff0c \uff0c \uff0c \uff0c \uff0c \uff0c \uff0c \uff0c \uff0c \uff0c \uff0c \uff0c \uff0c \uff0c \uff0c \uff0c \uff0c \uff0c \uff0c ...</td>\n    </tr>\n    <tr>\n      <th>99</th>\n      <td>Q100</td>\n      <td>\u7684 \u7684 \u7684 \u7684 \u7684 \u7684 \u7684 \u7684 \u7684 \u7684 \u7684 \u7684 \u7684 \u7684 \u7684 \u7684 \u7684 \u7684 \u7684 \u7684 \u7684 \u7684 \u7684 ...</td>\n    </tr>\n  </tbody>\n</table>\n<p>100 rows \u00d7 2 columns</p>\n</div>"}, "metadata": {}}]}, {"metadata": {}, "cell_type": "markdown", "source": "\u8fd0\u884c\u7ed3\u679c\u4e0d\u7406\u60f3\uff0c\u5e94\u8be5\u662ftrain\u7684epoch\u4e0d\u591f\uff0c\u53ea\u7528\u4e86\u4e00\u4e2aepoch\uff0c\u6253\u7b97\u4e4b\u540e\u4f18\u5316\u5b8c\u518d\u8dd1\u3002\u8dd1\u4e00\u6b21\u592a\u4e45\u4e86\u3002"}, {"metadata": {"trusted": true}, "cell_type": "code", "source": "", "execution_count": null, "outputs": []}], "metadata": {"kernelspec": {"name": "tensorflow-1.13.1", "display_name": "TensorFlow-1.13.1", "language": "python"}, "language_info": {"name": "python", "version": "3.6.4", "mimetype": "text/x-python", "codemirror_mode": {"name": "ipython", "version": 3}, "pygments_lexer": "ipython3", "nbconvert_exporter": "python", "file_extension": ".py"}}, "nbformat": 4, "nbformat_minor": 4}