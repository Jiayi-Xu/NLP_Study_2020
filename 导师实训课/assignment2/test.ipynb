{
 "cells": [
  {
   "cell_type": "code",
   "execution_count": 1,
   "metadata": {},
   "outputs": [
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "Collecting tensorflow-gpu==2.0.0b1\n",
      "  Downloading http://repo.myhuaweicloud.com/repository/pypi/packages/2b/53/e18c5e7a2263d3581a979645a185804782e59b8e13f42b9c3c3cfb5bb503/tensorflow_gpu-2.0.0b1-cp36-cp36m-manylinux1_x86_64.whl (348.9MB)\n",
      "\u001b[K    100% |████████████████████████████████| 348.9MB 31.1MB/s ta 0:00:011  0% |▏                               | 2.1MB 79.5MB/s eta 0:00:05[K    1% |▋                               | 6.8MB 90.6MB/s eta 0:00:04              | 10.5MB 96.5MB/s eta 0:00:040:04:00:04      | 24.8MB 101.8MB/s eta 0:00:040:05.1MB/s eta 0:00:04                     | 39.9MB 92.5MB/s eta 0:00:04                     | 44.1MB 85.3MB/s eta 0:00:04MB/s eta 0:00:04MB/s eta 0:00:04██▌                          | 59.4MB 98.5MB/s eta 0:00:03         | 63.6MB 94.0MB/s eta 0:00:043MB 94.4MB/s eta 0:00:034MB 92.1MB/s eta 0:00:041MB 89.4MB/s eta 0:00:04                     | 81.0MB 91.7MB/s eta 0:00:03��████▉                        | 86.0MB 96.9MB/s eta 0:00:034MB 93.4MB/s eta 0:00:03                   | 94.5MB 95.2MB/s eta 0:00:03��██████                       | 98.9MB 90.8MB/s eta 0:00:03███████▌                      | 103.1MB 97.4MB/s eta 0:00:03   30% |██████████                      | 108.0MB 95.8MB/s eta 0:00:03       | 112.0MB 72.7MB/s eta 0:00:04                     | 116.4MB 96.6MB/s eta 0:00:03         | 118.1MB 109.0MB/s eta 0:00:03��████████▎                    | 122.5MB 93.1MB/s eta 0:00:03██▋                    | 126.2MB 91.0MB/s eta 0:00:03██████████                    | 130.4MB 97.4MB/s eta 0:00:03��▎                   | 134.3MB 103.3MB/s eta 0:00:03            | 138.2MB 93.9MB/s eta 0:00:0374.3MB/s eta 0:00:03███▌                  | 146.7MB 94.6MB/s eta 0:00:03███▉                  | 150.7MB 95.7MB/s eta 0:00:03�█████████████▎                 | 155.1MB 99.4MB/s eta 0:00:02   45% |██████████████▋                 | 159.8MB 91.3MB/s eta 0:00:03% |███████████████                 | 164.2MB 94.9MB/s eta 0:00:02   | 168.2MB 92.7MB/s eta 0:00:02    | 172.4MB 95.9MB/s eta 0:00:02��███████▏               | 176.2MB 93.3MB/s eta 0:00:02   51% |████████████████▋               | 180.7MB 87.6MB/s eta 0:00:02��████████               | 184.4MB 86.8MB/s eta 0:00:02[K    53% |█████████████████▎              | 187.9MB 98.3MB/s eta 0:00:02K    57% |██████████████████▎             | 199.3MB 99.4MB/s eta 0:00:02 |██████████████████▋             | 203.2MB 96.4MB/s eta 0:00:02�█████████             | 207.2MB 92.2MB/s eta 0:00:02�██████████▍            | 210.9MB 99.3MB/s eta 0:00:02��█▋            | 214.3MB 94.4MB/s eta 0:00:02█████            | 218.0MB 99.6MB/s eta 0:00:02��█████████████████▍           | 221.7MB 90.7MB/s eta 0:00:02█████████████████▊           | 225.4MB 97.3MB/s eta 0:00:02% |█████████████████████           | 229.0MB 98.3MB/s eta 0:00:028MB 100.2MB/s eta 0:00:02MB 58.7MB/s eta 0:00:020:02█████▎         | 242.4MB 100.0MB/s eta 0:00:02[K    70% |██████████████████████▋         | 246.1MB 96.0MB/s eta 0:00:02�██████         | 249.7MB 98.0MB/s eta 0:00:02██████▏        | 252.9MB 98.0MB/s eta 0:00:01��████████████████▋        | 257.1MB 95.5MB/s eta 0:00:01�███████████        | 261.1MB 83.0MB/s eta 0:00:02101�████████▏      | 274.7MB 95.9MB/s eta 0:00:01��████████▌      | 278.4MB 87.3MB/s eta 0:00:010% |█████████████████████████▉      | 281.1MB 89.9MB/s eta 0:00:01�███████▏     | 284.9MB 86.9MB/s eta 0:00:01:01��████████▉     | 292.0MB 96.9MB/s eta 0:00:01�████████     | 294.9MB 70.2MB/s eta 0:00:01████████▊    | 301.8MB 98.3MB/s eta 0:00:01��████████████████████    | 304.9MB 89.0MB/s eta 0:00:01% |████████████████████████████▎   | 307.8MB 89.5MB/s eta 0:00:01████████████████████████████▌   | 311.2MB 97.5MB/s eta 0:00:01    90% |████████████████████████████▉   | 314.5MB 95.2MB/s eta 0:00:01�█████████████▏  | 317.8MB 96.6MB/s eta 0:00:01.6MB 67.7MB/s eta 0:00:01███████████████  | 326.7MB 97.8MB/s eta 0:00:01███████▏ | 329.4MB 83.3MB/s eta 0:00:01███████▍ | 331.8MB 96.2MB/s eta 0:00:01███████▊ | 335.4MB 97.0MB/s eta 0:00:01████████ | 338.8MB 100.0MB/s eta 0:00:01▎| 341.5MB 88.4MB/s eta 0:00:01███████████████████| 348.3MB 108.4MB/s eta 0:00:01\n",
      "\u001b[?25hRequirement already satisfied: wheel>=0.26 in /home/ma-user/anaconda3/envs/TensorFlow-1.13.1/lib/python3.6/site-packages (from tensorflow-gpu==2.0.0b1)\n",
      "Collecting tf-estimator-nightly<1.14.0.dev2019060502,>=1.14.0.dev2019060501 (from tensorflow-gpu==2.0.0b1)\n",
      "  Downloading http://repo.myhuaweicloud.com/repository/pypi/packages/32/dd/99c47dd007dcf10d63fd895611b063732646f23059c618a373e85019eb0e/tf_estimator_nightly-1.14.0.dev2019060501-py2.py3-none-any.whl (496kB)\n",
      "\u001b[K    100% |████████████████████████████████| 501kB 103.8MB/s ta 0:00:01\n",
      "\u001b[?25hCollecting wrapt>=1.11.1 (from tensorflow-gpu==2.0.0b1)\n",
      "  Downloading http://repo.myhuaweicloud.com/repository/pypi/packages/82/f7/e43cefbe88c5fd371f4cf0cf5eb3feccd07515af9fd6cf7dbf1d1793a797/wrapt-1.12.1.tar.gz\n",
      "Requirement already satisfied: keras-preprocessing>=1.0.5 in /home/ma-user/anaconda3/envs/TensorFlow-1.13.1/lib/python3.6/site-packages (from tensorflow-gpu==2.0.0b1)\n",
      "Requirement already satisfied: keras-applications>=1.0.6 in /home/ma-user/anaconda3/envs/TensorFlow-1.13.1/lib/python3.6/site-packages (from tensorflow-gpu==2.0.0b1)\n",
      "Collecting tb-nightly<1.14.0a20190604,>=1.14.0a20190603 (from tensorflow-gpu==2.0.0b1)\n",
      "  Downloading http://repo.myhuaweicloud.com/repository/pypi/packages/a4/96/571b875cd81dda9d5dfa1422a4f9d749e67c0a8d4f4f0b33a4e5f5f35e27/tb_nightly-1.14.0a20190603-py3-none-any.whl (3.1MB)\n",
      "\u001b[K    100% |████████████████████████████████| 3.1MB 99.2MB/s eta 0:00:01��▍| 3.1MB 105.1MB/s eta 0:00:01\n",
      "\u001b[?25hRequirement already satisfied: grpcio>=1.8.6 in /home/ma-user/anaconda3/envs/TensorFlow-1.13.1/lib/python3.6/site-packages (from tensorflow-gpu==2.0.0b1)\n",
      "Requirement already satisfied: termcolor>=1.1.0 in /home/ma-user/anaconda3/envs/TensorFlow-1.13.1/lib/python3.6/site-packages (from tensorflow-gpu==2.0.0b1)\n",
      "Collecting absl-py>=0.7.0 (from tensorflow-gpu==2.0.0b1)\n",
      "  Downloading http://repo.myhuaweicloud.com/repository/pypi/packages/1a/53/9243c600e047bd4c3df9e69cfabc1e8004a82cac2e0c484580a78a94ba2a/absl-py-0.9.0.tar.gz (104kB)\n",
      "\u001b[K    100% |████████████████████████████████| 112kB 99.0MB/s ta 0:00:01\n",
      "\u001b[?25hRequirement already satisfied: gast>=0.2.0 in /home/ma-user/anaconda3/envs/TensorFlow-1.13.1/lib/python3.6/site-packages (from tensorflow-gpu==2.0.0b1)\n",
      "Requirement already satisfied: astor>=0.6.0 in /home/ma-user/anaconda3/envs/TensorFlow-1.13.1/lib/python3.6/site-packages (from tensorflow-gpu==2.0.0b1)\n",
      "Requirement already satisfied: six>=1.10.0 in /home/ma-user/anaconda3/envs/TensorFlow-1.13.1/lib/python3.6/site-packages (from tensorflow-gpu==2.0.0b1)\n",
      "Collecting google-pasta>=0.1.6 (from tensorflow-gpu==2.0.0b1)\n",
      "  Downloading http://repo.myhuaweicloud.com/repository/pypi/packages/a3/de/c648ef6835192e6e2cc03f40b19eeda4382c49b5bafb43d88b931c4c74ac/google_pasta-0.2.0-py3-none-any.whl (57kB)\n",
      "\u001b[K    100% |████████████████████████████████| 61kB 77.9MB/s ta 0:00:01\n",
      "\u001b[?25hRequirement already satisfied: numpy<2.0,>=1.14.5 in /home/ma-user/anaconda3/envs/TensorFlow-1.13.1/lib/python3.6/site-packages (from tensorflow-gpu==2.0.0b1)\n",
      "Requirement already satisfied: protobuf>=3.6.1 in /home/ma-user/anaconda3/envs/TensorFlow-1.13.1/lib/python3.6/site-packages (from tensorflow-gpu==2.0.0b1)\n",
      "Requirement already satisfied: h5py in /home/ma-user/anaconda3/envs/TensorFlow-1.13.1/lib/python3.6/site-packages (from keras-applications>=1.0.6->tensorflow-gpu==2.0.0b1)\n",
      "Requirement already satisfied: setuptools>=41.0.0 in /home/ma-user/anaconda3/envs/TensorFlow-1.13.1/lib/python3.6/site-packages (from tb-nightly<1.14.0a20190604,>=1.14.0a20190603->tensorflow-gpu==2.0.0b1)\n",
      "Requirement already satisfied: markdown>=2.6.8 in /home/ma-user/anaconda3/envs/TensorFlow-1.13.1/lib/python3.6/site-packages (from tb-nightly<1.14.0a20190604,>=1.14.0a20190603->tensorflow-gpu==2.0.0b1)\n",
      "Requirement already satisfied: werkzeug>=0.11.15 in /home/ma-user/anaconda3/envs/TensorFlow-1.13.1/lib/python3.6/site-packages (from tb-nightly<1.14.0a20190604,>=1.14.0a20190603->tensorflow-gpu==2.0.0b1)\n",
      "Building wheels for collected packages: wrapt, absl-py\n",
      "  Running setup.py bdist_wheel for wrapt ... \u001b[?25ldone\n",
      "\u001b[?25h  Stored in directory: /home/ma-user/.cache/pip/wheels/a7/47/3e/319c41219c933f06ddb6c4227c5a0d7523b8a3ea114664dd06\n",
      "  Running setup.py bdist_wheel for absl-py ... \u001b[?25ldone\n",
      "\u001b[?25h  Stored in directory: /home/ma-user/.cache/pip/wheels/32/8f/6b/3b21b4a9c89d56416e593a3257364e3afc7db8bd5d50bd1548\n",
      "Successfully built wrapt absl-py\n",
      "Installing collected packages: tf-estimator-nightly, wrapt, absl-py, tb-nightly, google-pasta, tensorflow-gpu\n",
      "  Found existing installation: wrapt 1.10.11\n",
      "\u001b[31m    DEPRECATION: Uninstalling a distutils installed project (wrapt) has been deprecated and will be removed in a future version. This is due to the fact that uninstalling a distutils project will only partially uninstall the project.\u001b[0m\n",
      "    Uninstalling wrapt-1.10.11:\n",
      "      Successfully uninstalled wrapt-1.10.11\n",
      "  Found existing installation: absl-py 0.2.2\n",
      "    Uninstalling absl-py-0.2.2:\n",
      "      Successfully uninstalled absl-py-0.2.2\n",
      "  Found existing installation: tensorflow-gpu 1.13.1\n",
      "    Uninstalling tensorflow-gpu-1.13.1:\n",
      "      Successfully uninstalled tensorflow-gpu-1.13.1\n",
      "Successfully installed absl-py-0.9.0 google-pasta-0.2.0 tb-nightly-1.14.0a20190603 tensorflow-gpu-2.0.0b1 tf-estimator-nightly-1.14.0.dev2019060501 wrapt-1.12.1\n",
      "\u001b[33mYou are using pip version 9.0.1, however version 20.1.1 is available.\n",
      "You should consider upgrading via the 'pip install --upgrade pip' command.\u001b[0m\n"
     ]
    }
   ],
   "source": [
    "# 安装tensorflow2.0\n",
    "!pip install tensorflow-gpu==2.0.0b1"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 1,
   "metadata": {},
   "outputs": [
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "2.0.0-beta1\n"
     ]
    }
   ],
   "source": [
    "import tensorflow as tf\n",
    "print(tf.__version__)"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 12,
   "metadata": {},
   "outputs": [
    {
     "data": {
      "text/plain": [
       "[PhysicalDevice(name='/physical_device:GPU:0', device_type='GPU')]"
      ]
     },
     "execution_count": 12,
     "metadata": {},
     "output_type": "execute_result"
    }
   ],
   "source": [
    "physical_devices = tf.config.experimental.list_physical_devices('GPU')\n",
    "physical_devices"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "# 以下代码执行时候参数配置信息如下：\n",
    "\n",
    "name | 价格 |  数量  \n",
    "-|-|-\n",
    "max_enc_len | 200 | 5 |\n",
    "max_dec_len | 40 | 6 |\n",
    "batch_size | 200 | 7 |\n",
    "vocab_size | 10000 | 7 |\n",
    "embed_size | 256 | 7 |\n",
    "enc_units | 256 | 7 |\n",
    "dec_units | 256 | 7 |\n",
    "attn_units | 256 | 7 |\n",
    "steps_per_epoch | 1 | 7 |\n",
    "epochs | 10 | 7 |"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 2,
   "metadata": {},
   "outputs": [
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "max_size of vocab was specified as 10000; we now have 10000 words. Stopping reading.\n",
      "Finished constructing vocabulary of 10000 total words. Last word added: 私\n",
      "true vocab is  10000\n",
      "Creating the batcher ...\n",
      "WARNING:tensorflow:From /home/ma-user/anaconda3/envs/TensorFlow-1.13.1/lib/python3.6/site-packages/tensorflow/python/data/ops/dataset_ops.py:505: py_func (from tensorflow.python.ops.script_ops) is deprecated and will be removed in a future version.\n",
      "Instructions for updating:\n",
      "tf.py_func is deprecated in TF V2. Instead, there are two\n",
      "    options available in V2.\n",
      "    - tf.py_function takes a python function which manipulates tf eager\n",
      "    tensors instead of numpy arrays. It's easy to convert a tf eager tensor to\n",
      "    an ndarray (just call tensor.numpy()) but having access to eager tensors\n",
      "    means `tf.py_function`s can use accelerators such as GPUs as well as\n",
      "    being differentiable using a gradient tape.\n",
      "    - tf.numpy_function maintains the semantics of the deprecated tf.py_func\n",
      "    (it is not differentiable, and manipulates numpy arrays). It drops the\n",
      "    stateful argument making all functions stateful.\n",
      "    \n",
      "Building the model ...\n",
      "WARNING:tensorflow:From /home/ma-user/work/test/seq2seq_tf2/encoders/rnn_encoder.py:38: The name tf.keras.layers.CuDNNGRU is deprecated. Please use tf.compat.v1.keras.layers.CuDNNGRU instead.\n",
      "\n",
      "Creating the checkpoint manager\n",
      "Initializing from scratch.\n",
      "Starting the training ...\n",
      "WARNING:tensorflow:From /home/ma-user/anaconda3/envs/TensorFlow-1.13.1/lib/python3.6/site-packages/tensorflow/python/ops/math_grad.py:1220: add_dispatch_support.<locals>.wrapper (from tensorflow.python.ops.array_ops) is deprecated and will be removed in a future version.\n",
      "Instructions for updating:\n",
      "Use tf.where in 2.0, which has the same broadcast rule as np.where\n",
      "Epoch 1 Batch 100 Loss 6.4773\n",
      "Epoch 1 Batch 200 Loss 6.2184\n",
      "Epoch 1 Batch 300 Loss 6.0554\n",
      "Epoch 1 Batch 400 Loss 5.9082\n",
      "Saving checkpoint for epoch 1 at /home/ma-user/work/test/ckpt/seq2seq/checkpoint/ckpt-1 ,best loss 5.888243675231934\n",
      "Epoch 1 Loss 5.8882\n",
      "Time taken for 1 epoch 397.12049412727356 sec\n",
      "\n",
      "Epoch 2 Batch 100 Loss 5.0965\n",
      "Epoch 2 Batch 200 Loss 5.0356\n",
      "Epoch 2 Batch 300 Loss 4.9934\n",
      "Epoch 2 Batch 400 Loss 4.9363\n",
      "Epoch 3 Batch 100 Loss 4.5208\n",
      "Epoch 3 Batch 200 Loss 4.4839\n",
      "Epoch 3 Batch 300 Loss 4.4712\n",
      "Epoch 3 Batch 400 Loss 4.4450\n",
      "Saving checkpoint for epoch 3 at /home/ma-user/work/test/ckpt/seq2seq/checkpoint/ckpt-2 ,best loss 4.439842700958252\n",
      "Epoch 3 Loss 4.4398\n",
      "Time taken for 1 epoch 396.7885580062866 sec\n",
      "\n",
      "Epoch 4 Batch 100 Loss 4.1772\n",
      "Epoch 4 Batch 200 Loss 4.1534\n",
      "Epoch 4 Batch 300 Loss 4.1543\n",
      "Epoch 4 Batch 400 Loss 4.1440\n",
      "Epoch 5 Batch 100 Loss 3.9456\n",
      "Epoch 5 Batch 200 Loss 3.9292\n",
      "Epoch 5 Batch 300 Loss 3.9378\n",
      "Epoch 5 Batch 400 Loss 3.9375\n",
      "Saving checkpoint for epoch 5 at /home/ma-user/work/test/ckpt/seq2seq/checkpoint/ckpt-3 ,best loss 3.935612678527832\n",
      "Epoch 5 Loss 3.9356\n",
      "Time taken for 1 epoch 390.69515347480774 sec\n",
      "\n",
      "Epoch 6 Batch 100 Loss 3.7800\n",
      "Epoch 6 Batch 200 Loss 3.7668\n",
      "Epoch 6 Batch 300 Loss 3.7796\n",
      "Epoch 6 Batch 400 Loss 3.7849\n",
      "Epoch 7 Batch 100 Loss 3.6505\n",
      "Epoch 7 Batch 200 Loss 3.6398\n",
      "Epoch 7 Batch 300 Loss 3.6547\n",
      "Epoch 7 Batch 400 Loss 3.6630\n",
      "Saving checkpoint for epoch 7 at /home/ma-user/work/test/ckpt/seq2seq/checkpoint/ckpt-4 ,best loss 3.6622798442840576\n",
      "Epoch 7 Loss 3.6623\n",
      "Time taken for 1 epoch 388.95069551467896 sec\n",
      "\n",
      "Epoch 8 Batch 100 Loss 3.5400\n",
      "Epoch 8 Batch 200 Loss 3.5341\n",
      "Epoch 8 Batch 300 Loss 3.5497\n",
      "Epoch 8 Batch 400 Loss 3.5598\n",
      "Epoch 9 Batch 100 Loss 3.4445\n",
      "Epoch 9 Batch 200 Loss 3.4442\n",
      "Epoch 9 Batch 300 Loss 3.4602\n",
      "Epoch 9 Batch 400 Loss 3.4720\n",
      "Saving checkpoint for epoch 9 at /home/ma-user/work/test/ckpt/seq2seq/checkpoint/ckpt-5 ,best loss 3.4714741706848145\n",
      "Epoch 9 Loss 3.4715\n",
      "Time taken for 1 epoch 384.0371572971344 sec\n",
      "\n",
      "Epoch 10 Batch 100 Loss 3.3641\n",
      "Epoch 10 Batch 200 Loss 3.3686\n",
      "Epoch 10 Batch 300 Loss 3.3853\n",
      "Epoch 10 Batch 400 Loss 3.3990\n"
     ]
    }
   ],
   "source": [
    "%run test/seq2seq_tf2/bin/main.py"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": []
  }
 ],
 "metadata": {
  "kernelspec": {
   "display_name": "TensorFlow-1.13.1",
   "language": "python",
   "name": "tensorflow-1.13.1"
  },
  "language_info": {
   "codemirror_mode": {
    "name": "ipython",
    "version": 3
   },
   "file_extension": ".py",
   "mimetype": "text/x-python",
   "name": "python",
   "nbconvert_exporter": "python",
   "pygments_lexer": "ipython3",
   "version": "3.6.4"
  }
 },
 "nbformat": 4,
 "nbformat_minor": 4
}
