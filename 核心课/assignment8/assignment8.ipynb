{
 "cells": [
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "# Assignment 8"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "#### 1. 复习上课内容"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "#### 2.理论题"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "##### 1.  What is semi-supervised learning ?"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "semi-supervised：\n",
    "\n",
    "+ 有标签数据\n",
    "$$\\{(x^{r},y\\_hat^{r})\\}^{R}_{r=1}$$\n",
    "+ 无标签数据\n",
    "$$\\{x^{u}\\}^{R+U}_{u=R}$$\n",
    "通常情况下 U>>R\n",
    "\n",
    "有未标注数据参与训练的学习，可以分为inductive learning 和 transductive learning\n",
    "\n",
    "+ 如果这个未标注数据同时也是测试数据，则是transductive learning\n",
    "+ 如果这个未标注数据只是用于帮助训练而不用于测试的话，则是inductive learning"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "##### 2. What is GMM ?"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "高斯混合模型GMM 用来表示在总体分布（distribution）中含有 K 个子分布的概率模型\n",
    "\n",
    "高斯混合模型的概率分布为：\n",
    "\n",
    "$$P(x|\\theta) = \\Sigma^K_{k=1} \\alpha_{k}\\phi(x|\\mu_{k},\\sigma_{k})$$\n",
    "\n",
    "K是混合模型中子高斯模型的数量，k=1,2,3...,K\n",
    "\n",
    "$\\alpha_{k}$是观测数据属于第k个子模型的概率, $\\Sigma^K_{k=1} \\alpha_{k} = 1$"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "##### 3. What are the diffreences between seed k-means and constrained k-means ?"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "+ Seeded K-Means:\n",
    "    + Labeled data provided by user are used for initialization: initial center for cluster 𝑖 is the mean of the seed points having label 𝑖\n",
    "    + Seed points are only used for initialization, and not in subsequent steps\n",
    "\n",
    "+ Constrained K-Means:  \n",
    "    + Labeled data provided by user are used to initialize K-Means algorithm.\n",
    "    + Cluster labels of seed data are kept unchanged in the cluster assignment steps, and only the labels of the non-seed data are re-estimated.\n",
    "\n",
    "\n",
    "+ 两个都是用有标签的数据做初始化\n",
    "    + Seeded K-Means的有标签数据会和无标签数据一样进行训练更新，有可能会在之后的步骤进行一定的更新\n",
    "    + Constrained K-Means会排除这些用来初始化的有标签数据(相信这些有标签的数据)。"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "##### 4. Please briefly describe what are self-training and co-training ? "
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "self-training 自我训练: 通过一系列的步骤，用已有的有标签的数据(labelled data)，去对剩下的还未标记的数据打标签。从而使得训练数据(training data)更多\n",
    "\n",
    "+ 用有标签数据$\\{(X_{1:n}, Y_{1:n})\\}$进行训练\n",
    "+ 用这个模型来对没有标签的数据做预测 predicr on $X_u$\n",
    "+ 选取最有把握的预测结果来标记数据(unlabelled data), 把新标记好的数据加入到原来的标记好的数据集中，同时把他们从原来的数据集中删除\n",
    "+ 不断重复,直到数据集不发生变化\n",
    "\n",
    "co-training 协同学习:\n",
    "\n",
    "假设有数据集，有多个特征，随机的把特征拆成两部分，每组数据有2个特征: x1 和 x2。其中有标签的那部分数据集为L:[x1,x2,y]，没有标签的数据集为U:[x1,x2]。\n",
    "\n",
    "初始化数据，把L 分为L1 ([x1,y]) 和L2 ([x2,y])\n",
    "\n",
    "重复, 直到数据集不发生变化\n",
    "\n",
    "+ 分别用L1和L2训练出一个模型 F1和F2\n",
    "+ 分别用模型F1和F2去预测U (给U打标签)（只选出最有把握的一些结果）\n",
    "+ 把F1预测的top-k结果放入L2，把F2预测的top-k结果放入L1 (交叉放置)\n",
    "+ 更新L 和 U，把他们从原来的数据集中删除\n",
    "\n",
    "\n"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "##### 5. What is active learning ?"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "让模型自动挑选出需要学习的数据\n",
    "+ 从一堆不带标签的数据中\n",
    "    + 主动选择一部分进行标注，而不是被动的。\n",
    "\n",
    "+ 每标注一次，模型重新或者增量的训练一次。\n",
    "\n",
    "+ 然后重复以上步骤"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "#### 3.实践题"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "Titanic: Machine Learning from Disaster"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "Data Source :https://www.kaggle.com/c/titanic/data"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "####  In this assignment, you have to build a predictive model that answers the question: “what sorts of people were more likely to survive?” using passenger data (ie name, age, gender, socio-economic class, etc)."
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "低： 完成。"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "高：准确率 95% 以上。"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 123,
   "metadata": {},
   "outputs": [],
   "source": [
    "import numpy as np\n",
    "import pandas as pd\n",
    "import xgboost as xgb"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 131,
   "metadata": {},
   "outputs": [],
   "source": [
    "train = pd.read_csv('datasets/train.csv')\n",
    "test = pd.read_csv('datasets/test.csv')"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 132,
   "metadata": {},
   "outputs": [
    {
     "data": {
      "text/html": [
       "<div>\n",
       "<style scoped>\n",
       "    .dataframe tbody tr th:only-of-type {\n",
       "        vertical-align: middle;\n",
       "    }\n",
       "\n",
       "    .dataframe tbody tr th {\n",
       "        vertical-align: top;\n",
       "    }\n",
       "\n",
       "    .dataframe thead th {\n",
       "        text-align: right;\n",
       "    }\n",
       "</style>\n",
       "<table border=\"1\" class=\"dataframe\">\n",
       "  <thead>\n",
       "    <tr style=\"text-align: right;\">\n",
       "      <th></th>\n",
       "      <th>PassengerId</th>\n",
       "      <th>Survived</th>\n",
       "      <th>Pclass</th>\n",
       "      <th>Name</th>\n",
       "      <th>Sex</th>\n",
       "      <th>Age</th>\n",
       "      <th>SibSp</th>\n",
       "      <th>Parch</th>\n",
       "      <th>Ticket</th>\n",
       "      <th>Fare</th>\n",
       "      <th>Cabin</th>\n",
       "      <th>Embarked</th>\n",
       "    </tr>\n",
       "  </thead>\n",
       "  <tbody>\n",
       "    <tr>\n",
       "      <th>0</th>\n",
       "      <td>1</td>\n",
       "      <td>0</td>\n",
       "      <td>3</td>\n",
       "      <td>Braund, Mr. Owen Harris</td>\n",
       "      <td>male</td>\n",
       "      <td>22.0</td>\n",
       "      <td>1</td>\n",
       "      <td>0</td>\n",
       "      <td>A/5 21171</td>\n",
       "      <td>7.2500</td>\n",
       "      <td>NaN</td>\n",
       "      <td>S</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <th>1</th>\n",
       "      <td>2</td>\n",
       "      <td>1</td>\n",
       "      <td>1</td>\n",
       "      <td>Cumings, Mrs. John Bradley (Florence Briggs Th...</td>\n",
       "      <td>female</td>\n",
       "      <td>38.0</td>\n",
       "      <td>1</td>\n",
       "      <td>0</td>\n",
       "      <td>PC 17599</td>\n",
       "      <td>71.2833</td>\n",
       "      <td>C85</td>\n",
       "      <td>C</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <th>2</th>\n",
       "      <td>3</td>\n",
       "      <td>1</td>\n",
       "      <td>3</td>\n",
       "      <td>Heikkinen, Miss. Laina</td>\n",
       "      <td>female</td>\n",
       "      <td>26.0</td>\n",
       "      <td>0</td>\n",
       "      <td>0</td>\n",
       "      <td>STON/O2. 3101282</td>\n",
       "      <td>7.9250</td>\n",
       "      <td>NaN</td>\n",
       "      <td>S</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <th>3</th>\n",
       "      <td>4</td>\n",
       "      <td>1</td>\n",
       "      <td>1</td>\n",
       "      <td>Futrelle, Mrs. Jacques Heath (Lily May Peel)</td>\n",
       "      <td>female</td>\n",
       "      <td>35.0</td>\n",
       "      <td>1</td>\n",
       "      <td>0</td>\n",
       "      <td>113803</td>\n",
       "      <td>53.1000</td>\n",
       "      <td>C123</td>\n",
       "      <td>S</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <th>4</th>\n",
       "      <td>5</td>\n",
       "      <td>0</td>\n",
       "      <td>3</td>\n",
       "      <td>Allen, Mr. William Henry</td>\n",
       "      <td>male</td>\n",
       "      <td>35.0</td>\n",
       "      <td>0</td>\n",
       "      <td>0</td>\n",
       "      <td>373450</td>\n",
       "      <td>8.0500</td>\n",
       "      <td>NaN</td>\n",
       "      <td>S</td>\n",
       "    </tr>\n",
       "  </tbody>\n",
       "</table>\n",
       "</div>"
      ],
      "text/plain": [
       "   PassengerId  Survived  Pclass  \\\n",
       "0            1         0       3   \n",
       "1            2         1       1   \n",
       "2            3         1       3   \n",
       "3            4         1       1   \n",
       "4            5         0       3   \n",
       "\n",
       "                                                Name     Sex   Age  SibSp  \\\n",
       "0                            Braund, Mr. Owen Harris    male  22.0      1   \n",
       "1  Cumings, Mrs. John Bradley (Florence Briggs Th...  female  38.0      1   \n",
       "2                             Heikkinen, Miss. Laina  female  26.0      0   \n",
       "3       Futrelle, Mrs. Jacques Heath (Lily May Peel)  female  35.0      1   \n",
       "4                           Allen, Mr. William Henry    male  35.0      0   \n",
       "\n",
       "   Parch            Ticket     Fare Cabin Embarked  \n",
       "0      0         A/5 21171   7.2500   NaN        S  \n",
       "1      0          PC 17599  71.2833   C85        C  \n",
       "2      0  STON/O2. 3101282   7.9250   NaN        S  \n",
       "3      0            113803  53.1000  C123        S  \n",
       "4      0            373450   8.0500   NaN        S  "
      ]
     },
     "execution_count": 132,
     "metadata": {},
     "output_type": "execute_result"
    }
   ],
   "source": [
    "train.head()"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 133,
   "metadata": {},
   "outputs": [
    {
     "data": {
      "text/plain": [
       "PassengerId      0\n",
       "Survived         0\n",
       "Pclass           0\n",
       "Name             0\n",
       "Sex              0\n",
       "Age            177\n",
       "SibSp            0\n",
       "Parch            0\n",
       "Ticket           0\n",
       "Fare             0\n",
       "Cabin          687\n",
       "Embarked         2\n",
       "dtype: int64"
      ]
     },
     "execution_count": 133,
     "metadata": {},
     "output_type": "execute_result"
    }
   ],
   "source": [
    "train.isna().sum()"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 134,
   "metadata": {},
   "outputs": [
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "        Survived\n",
      "Sex             \n",
      "female  0.742038\n",
      "male    0.188908\n"
     ]
    }
   ],
   "source": [
    "# 性别对存活率的影响， 妇女小孩优先的原则，增加判断是否child的feature\n",
    "print(train[['Sex','Survived']].groupby(['Sex']).mean())"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 135,
   "metadata": {},
   "outputs": [
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "             Fare\n",
      "Pclass           \n",
      "1       84.154687\n",
      "2       20.662183\n",
      "3       13.675550\n"
     ]
    }
   ],
   "source": [
    "# 船舱和fare的关系\n",
    "print(train[['Pclass','Fare']].groupby(['Pclass']).mean())"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "### 数据预处理"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 136,
   "metadata": {},
   "outputs": [],
   "source": [
    "def processing(titanic):\n",
    "    #对于年龄为空的数据 填充年龄中位数\n",
    "    titanic[\"Age\"] = titanic[\"Age\"].fillna(titanic[\"Age\"].median())\n",
    "    # child 妇女儿童优先\n",
    "    titanic[\"child\"] = titanic[\"Age\"].apply(lambda x: 1 if x < 15 else 0)\n",
    "    # sex 把性别从字符串类型转换为0或1数值型数据\n",
    "    titanic[\"Sex\"] = titanic[\"Sex\"].apply(lambda x: 1 if x == \"male\" else 0)\n",
    "    # familysize 家庭成员人数 兄弟姐妹父母配偶加自己\n",
    "    titanic[\"fimalysize\"] = titanic[\"SibSp\"] + titanic[\"Parch\"] + 1\n",
    "    # 对于fare为空的数据 根据船舱等级填充fare中位数\n",
    "    titanic[\"Fare\"] = titanic[\"Fare\"].fillna(titanic[\"Fare\"].median())\n",
    "    # 根据不同船舱等级对应的船票均值来对缺失的船票进行赋值\n",
    "    fare = [0,0,0]\n",
    "    for level in range(0, 3):\n",
    "        fare[level] = titanic[titanic.Pclass == level + 1]['Fare'].dropna().median()\n",
    "    for level in range(0, 3):\n",
    "        titanic.loc[(titanic.Fare.isnull()) & (titanic.Pclass == level + 1), 'Fare'] = fare[level]\n",
    "    return titanic\n",
    "# 对数据进行预处理\n",
    "train_data = processing(train)\n",
    "test_data = processing(test)"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 138,
   "metadata": {},
   "outputs": [
    {
     "data": {
      "text/plain": [
       "PassengerId      0\n",
       "Survived         0\n",
       "Pclass           0\n",
       "Name             0\n",
       "Sex              0\n",
       "Age              0\n",
       "SibSp            0\n",
       "Parch            0\n",
       "Ticket           0\n",
       "Fare             0\n",
       "Cabin          687\n",
       "Embarked         2\n",
       "child            0\n",
       "fimalysize       0\n",
       "dtype: int64"
      ]
     },
     "execution_count": 138,
     "metadata": {},
     "output_type": "execute_result"
    }
   ],
   "source": [
    "train_data.isna().sum()"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 139,
   "metadata": {},
   "outputs": [
    {
     "name": "stderr",
     "output_type": "stream",
     "text": [
      "/Users/maytone/anaconda3/lib/python3.7/site-packages/ipykernel_launcher.py:2: FutureWarning: Method .as_matrix will be removed in a future version. Use .values instead.\n",
      "  \n"
     ]
    }
   ],
   "source": [
    "# 选取特征 Cabin字段缺失数据多\n",
    "X_train = train_data[['Sex', 'Age', 'Pclass', 'SibSp', 'Parch', 'Fare','child','fimalysize']].as_matrix()"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 140,
   "metadata": {},
   "outputs": [],
   "source": [
    "Y_train = train['Survived']"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 141,
   "metadata": {},
   "outputs": [],
   "source": [
    "#训练模型\n",
    "model = xgb.XGBClassifier(max_depth=2, n_estimators=20, learning_rate=0.01).fit(X_train, Y_train)"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 142,
   "metadata": {},
   "outputs": [
    {
     "name": "stderr",
     "output_type": "stream",
     "text": [
      "/Users/maytone/anaconda3/lib/python3.7/site-packages/ipykernel_launcher.py:1: FutureWarning: Method .as_matrix will be removed in a future version. Use .values instead.\n",
      "  \"\"\"Entry point for launching an IPython kernel.\n"
     ]
    }
   ],
   "source": [
    "X_test = test_data[['Sex', 'Age', 'Pclass', 'SibSp', 'Parch', 'Fare','child','fimalysize']].as_matrix()"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 143,
   "metadata": {},
   "outputs": [
    {
     "data": {
      "text/plain": [
       "(XGBClassifier(base_score=0.5, booster='gbtree', colsample_bylevel=1,\n",
       "               colsample_bynode=1, colsample_bytree=1, gamma=0, gpu_id=-1,\n",
       "               importance_type='gain', interaction_constraints='',\n",
       "               learning_rate=0.1, max_delta_step=0, max_depth=6,\n",
       "               min_child_weight=1, missing=nan, monotone_constraints='()',\n",
       "               n_estimators=38, n_jobs=0, num_parallel_tree=1,\n",
       "               objective='binary:logistic', random_state=0, reg_alpha=0,\n",
       "               reg_lambda=1, scale_pos_weight=1, subsample=1,\n",
       "               tree_method='exact', validate_parameters=1, verbosity=None),\n",
       " {'learning_rate': 0.1, 'max_depth': 6, 'n_estimators': 38},\n",
       " 0.8428731762065096)"
      ]
     },
     "execution_count": 143,
     "metadata": {},
     "output_type": "execute_result"
    }
   ],
   "source": [
    "# 调参\n",
    "from sklearn.model_selection import GridSearchCV\n",
    "param_test = {\n",
    "    'n_estimators':range(20,60,2),\n",
    "    'max_depth': range(2, 10, 1),\n",
    "    'learning_rate': list((0.1,0.05,0.01))\n",
    "}\n",
    "grid_search = GridSearchCV(estimator = model, param_grid = param_test, \n",
    "scoring='accuracy', cv=5)\n",
    "grid_search.fit(X_train, Y_train)\n",
    "grid_search.best_estimator_, grid_search.best_params_, grid_search.best_score_"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 144,
   "metadata": {},
   "outputs": [],
   "source": [
    "lr = grid_search.best_params_['learning_rate']\n",
    "m_depth = grid_search.best_params_['max_depth']\n",
    "n_estima = grid_search.best_params_['n_estimators']"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 146,
   "metadata": {},
   "outputs": [],
   "source": [
    "#评估模型\n",
    "model = xgb.XGBClassifier(max_depth=m_depth, n_estimators=n_estima, learning_rate=lr).fit(X_train, Y_train)\n",
    "predictions = model.predict(X_test)\n",
    "\n",
    "# 保存预测结果\n",
    "submission = pd.DataFrame({ 'PassengerId': test['PassengerId'],\n",
    "                            'Survived': predictions })\n",
    "submission.to_csv(\"titanic_xgboost_submission4.csv\", index=False)"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "最终kaggle只有0.77"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": []
  }
 ],
 "metadata": {
  "kernelspec": {
   "display_name": "Python 3",
   "language": "python",
   "name": "python3"
  },
  "language_info": {
   "codemirror_mode": {
    "name": "ipython",
    "version": 3
   },
   "file_extension": ".py",
   "mimetype": "text/x-python",
   "name": "python",
   "nbconvert_exporter": "python",
   "pygments_lexer": "ipython3",
   "version": "3.7.3"
  }
 },
 "nbformat": 4,
 "nbformat_minor": 2
}
