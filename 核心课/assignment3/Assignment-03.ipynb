{
 "cells": [
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "# 思考题-homework？    \n",
    "#### 如何在不带空格的时候完成自动修整？--> 如何完成拼音的自动分割？   \n",
    "###### 提示：使用第一节课提到的语言模型!\n",
    "\n",
    "woyaoshangqinghua\n",
    "\n",
    "w yaoshangqinghua\n",
    "\n",
    "wo yaoshangqinghua\n",
    "\n",
    "woyao shangqinghua\n",
    "\n",
    "-> DP"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "# 思路\n",
    "\n",
    "\n",
    "+ 导入pinyin包 读取数据文件article_9k.txt和comments.txt文件转成拼音形式 存储到变量TOKEN_1_GRAM\n",
    "+ 统计词典里各个拼音的频数 Counter(TOKEN_1_GRAM) 存储到变量 words_count_1\n",
    "+ words_count_1 用于计算1-gram语言模型返回word的概率值 和 拼音自动纠错函数\n",
    "+ 定义pinyin_split函数，\n",
    "    + 判断n长度的word的概率值，再判断n-1长度的概率值，不断找最优值\n",
    "    + 将word拆分计算最优结果返回概率值和i索引\n",
    "+ 定义parse_solution函数将solution结果回溯出来\n",
    "+ 再将解析的solution结果传到拼音纠错函数correct_sequence_pinyin进行最终校验"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 226,
   "metadata": {},
   "outputs": [],
   "source": [
    "# 导入需要用到的包\n",
    "import pinyin\n",
    "from collections import Counter, defaultdict\n",
    "import pandas as pd\n",
    "import re\n",
    "from collections import Counter"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 229,
   "metadata": {},
   "outputs": [],
   "source": [
    "# 定义函数：调用pinyin包把中文转换成英文\n",
    "def chinese_to_pinyin(character):\n",
    "    return pinyin.get(character, format='strip', delimiter=' ')\n",
    "\n",
    "# 定义函数：将已经转换为pinyin的文本排除掉数字，返回格式为词列表\n",
    "def tokens(text):\n",
    "    \"List all the pinyin characters\"\n",
    "    return re.findall('[a-z]+',text.lower())"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 23,
   "metadata": {},
   "outputs": [],
   "source": [
    "TOKEN_1_GRAM = []\n",
    "for line in (open('./datasets/comments.txt')):   \n",
    "    TOKEN_1_GRAM += tokens(chinese_to_pinyin(line))"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 24,
   "metadata": {},
   "outputs": [],
   "source": [
    "for line in (open('./datasets/article_9k.txt')):\n",
    "    TOKEN_1_GRAM += tokens(chinese_to_pinyin(line))"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 233,
   "metadata": {},
   "outputs": [
    {
     "data": {
      "text/plain": [
       "['wu', 'jing', 'yi', 'yin', 'dao', 'le', 'nao', 'can', 'de', 'di']"
      ]
     },
     "execution_count": 233,
     "metadata": {},
     "output_type": "execute_result"
    }
   ],
   "source": [
    "# 展示单个词例子\n",
    "TOKEN_1_GRAM[:10]"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 234,
   "metadata": {},
   "outputs": [
    {
     "data": {
      "text/plain": [
       "[('de', 1195679),\n",
       " ('shi', 1173105),\n",
       " ('yi', 885644),\n",
       " ('ji', 728882),\n",
       " ('n', 717796),\n",
       " ('zhi', 492174),\n",
       " ('guo', 487083),\n",
       " ('zhong', 474720),\n",
       " ('bu', 442553),\n",
       " ('li', 423343)]"
      ]
     },
     "execution_count": 234,
     "metadata": {},
     "output_type": "execute_result"
    }
   ],
   "source": [
    "words_count_1 = Counter(TOKEN_1_GRAM)\n",
    "words_count_1.most_common(10)"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 235,
   "metadata": {},
   "outputs": [],
   "source": [
    "# 用words_count_1计算每个拼音出现的概率，这里对不存在的拼音概率设置为了0\n",
    "def get_probablity_1gram(word):\n",
    "    # 1-gram模型\n",
    "    if word in words_count_1:\n",
    "        \n",
    "        probability = words_count_1[word] / len(TOKEN_1_GRAM)\n",
    "#         print(\"存在\",word,probability)\n",
    "    else:\n",
    "        # 使用平滑法对不存在的词进行处理\n",
    "        probability = 0  # 1 / len(TOKEN_1_GRAM)\n",
    "#         print(\"不存在\",word,probability)\n",
    "\n",
    "    return  probability"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "# 定义主函数 \n",
    "\n",
    "+ 使用动态规划 统计一个words按word[:i]和word[i:]拆分后的概率，返回概率最大的结果\n",
    "+ 记录拆分概率最大结果的i位置到solution\n",
    "+ 解析solution获得拼音切分结果"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 237,
   "metadata": {},
   "outputs": [],
   "source": [
    "# 拼音切分\n",
    "def pinyin_split(word):\n",
    "    if word in memory:\n",
    "        return memory[word]\n",
    "    else:\n",
    "        # 使用 pinyin_split(word[:i]) * pinyin_split(word[i:]概率连乘获得拆分后拼音的概率值\n",
    "        max_prob, pos = max( [(get_probablity_1gram(word), len(word))] \n",
    "                            + [( pinyin_split(word[:i]) * pinyin_split(word[i:]), i) for i in range(1,len(word))])\n",
    "        # 按pos拆分概率最大，存储到字典solution\n",
    "        solution[word] = (word[:pos], word[pos:])\n",
    "        \n",
    "        memory[word] = max_prob\n",
    "        \n",
    "        return max_prob\n",
    "# 解析words拆分路径\n",
    "def parse_solution(word):\n",
    "    left_split, right_split = solution[word]\n",
    "    \n",
    "    if right_split == '': return [left_split]\n",
    "    \n",
    "    return parse_solution(left_split) + parse_solution(right_split)"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 254,
   "metadata": {},
   "outputs": [
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "使用语言模型拆分连续拼音的结果为:\n",
      " ['wo', 'yao', 'shang', 'qing', 'hua']\n"
     ]
    }
   ],
   "source": [
    "# 初始化变量 \n",
    "# memory存储各个word的概率值\n",
    "memory = {}\n",
    "# solution存储概率最大的拆分结果\n",
    "solution = {}\n",
    "# 设定需要拆分的拼音字符串\n",
    "word = 'woyaoshangqinghua'\n",
    "pinyin_split(word)\n",
    "\n",
    "parsed_solution = parse_solution(word)\n",
    "print(\"使用语言模型拆分连续拼音的结果为:\\n\",parsed_solution)"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "# 对解析好的拼音切分结果再进行自动纠错"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 248,
   "metadata": {},
   "outputs": [],
   "source": [
    "alphabet = 'abcdefghijklmnopqrstuvwxyz'\n",
    "\n",
    "def splits(word):\n",
    "    'Return a list of all possible (first, rest) pairs that comprise pinyin.'\n",
    "    return [(word[:i], word[i:])\n",
    "           for i in range(len(word)+1)]\n",
    "\n",
    "def known(words):\n",
    "    'Return the pinyin in our data'\n",
    "#     PINYIN_COUNT修改为words_count_1\n",
    "    return {w for w in words if w in words_count_1}\n",
    "\n",
    "def edits0(word):\n",
    "    'Return all strings that are zero edits away from word (i.e., just word itself).'\n",
    "    return {word}\n",
    "\n",
    "def edits1(word):\n",
    "    'Return all strings that are one edit away from this pinyin.'\n",
    "    pairs = splits(word)\n",
    "    deletes = [a+b[1:] for (a,b) in pairs if b]\n",
    "    transposes = [a+b[1]+b[0]+b[2:] for (a,b) in pairs if len(b) > 1]\n",
    "    replaces = [a+c+b[1:] for (a,b) in pairs for c in alphabet if b]\n",
    "    inserts = [a+c+b for (a,b) in pairs for c in alphabet]\n",
    "    return set(deletes + transposes + replaces + inserts)\n",
    "# 编辑距离为1的词上再加一个编辑距离\n",
    "def edits2(word):\n",
    "    'Return all strings that are two edits away from this pinyin.'\n",
    "    return {e2 for e1 in edits1(word) for e2 in edits1(e1)}"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 249,
   "metadata": {},
   "outputs": [],
   "source": [
    "def correct(word):\n",
    "    'Find the most possible pinyin based on edit distance'\n",
    "    # Prefer edit distance 0, then 1, then 2; otherwist default to word itself\n",
    "    # 找出与它编辑距离为0，1，2的词\n",
    "    # 注释了[word] 效果等同于known(edits0(word))\n",
    "    candidates = (known(edits0(word)) or \n",
    "                  known(edits1(word)) or\n",
    "                  known(edits2(word)))\n",
    "    # 返回出现次数最多的candidate\n",
    "    #     PINYIN_COUNT修改为 words_count_1\n",
    "    return max(candidates, key=words_count_1.get)"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 250,
   "metadata": {},
   "outputs": [],
   "source": [
    "def correct_sequence_pinyin(parsed_solution):\n",
    "#     把correct函数作用在text里的每一个词上面\n",
    "    return ' '.join(map(correct, parsed_solution))"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 253,
   "metadata": {},
   "outputs": [
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "经过拼音纠错后最终输出结果为：\n",
      " wo yao shang qing hua\n"
     ]
    }
   ],
   "source": [
    "result = correct_sequence_pinyin(parsed_solution)\n",
    "\n",
    "print(\"经过拼音纠错后最终输出结果为：\\n\",result)"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": []
  }
 ],
 "metadata": {
  "kernelspec": {
   "display_name": "Python 3",
   "language": "python",
   "name": "python3"
  },
  "language_info": {
   "codemirror_mode": {
    "name": "ipython",
    "version": 3
   },
   "file_extension": ".py",
   "mimetype": "text/x-python",
   "name": "python",
   "nbconvert_exporter": "python",
   "pygments_lexer": "ipython3",
   "version": "3.7.3"
  }
 },
 "nbformat": 4,
 "nbformat_minor": 2
}
